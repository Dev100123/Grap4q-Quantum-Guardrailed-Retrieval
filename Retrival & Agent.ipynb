{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a1ce59",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVAL 3\n",
    "# %% LEAK-FREE RETRIEVAL ABLATION — FULL DIAGNOSTICS (same artifacts as before)\n",
    "# Selection uses TRAIN only (no leakage); all plots/CSVs match your earlier names.\n",
    "#\n",
    "# Artifacts in results/qeval_ablation_plus/ :\n",
    "#   ├─ ablation_all_raw.csv\n",
    "#   ├─ ablation_macro_means.csv\n",
    "#   ├─ ablation_delta_vs_baseline.csv\n",
    "#   ├─ ablation_diag_macro_means.csv\n",
    "#   ├─ main_effect_*.csv\n",
    "#   ├─ best_config.txt\n",
    "#   ├─ abl_macro_heatmap.png\n",
    "#   ├─ abl_macro_heatmap_extra.png\n",
    "#   ├─ abl_delta_heatmap.png\n",
    "#   ├─ abl_ast_subset_bars.png\n",
    "#   ├─ abl_main_effect_*.png\n",
    "#   ├─ abl_ecdf_*_baseline_vs_best.png\n",
    "#   ├─ abl_rank_breakdown_baseline_vs_best.png\n",
    "#   ├─ abl_diag_heatmap_z.png\n",
    "#   ├─ abl_main_effect_hints_diag.png\n",
    "#   ├─ scatter_synprior_vs_precproxy_best.png\n",
    "#   └─ scatter_qdensity_vs_ndcg_best.png\n",
    "#\n",
    "# Also writes: splits_70_25_5.json and macro_by_split.csv (best cfg on TRAIN/VAL/TEST)\n",
    "\n",
    "%pip install -q pandas numpy matplotlib sentence-transformers tqdm\n",
    "\n",
    "import os, re, json, math, difflib, ast, random\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "from hashlib import md5\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams.update({\"axes.spines.top\": False, \"axes.spines.right\": False})\n",
    "\n",
    "# ------------------------------- knobs -------------------------------\n",
    "DB_ROOT = Path(\"data/bugs4q/Bugs4Q-Database\")\n",
    "SAVE    = Path(\"results/qeval_ablation_plus\"); SAVE.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 7; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "TOPK         = 2\n",
    "OVERRETRIEVE = 80\n",
    "DATA_PERCENT = 100          # % of TRAIN used in the grid (speed knob)\n",
    "RERANK_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "# IDF scope used during selection (prevents leakage)\n",
    "INDEX_SCOPE_FOR_ABLATION = \"train\"   # {\"train\",\"all\"}\n",
    "\n",
    "# ------------------------------- utils -------------------------------\n",
    "WORD_RE   = re.compile(r\"[A-Za-z_][A-Za-z_0-9]*\")\n",
    "STOPWORDS = set(\"a an and are as at be by for from has have in is it its of on or that the to was were will with not this self none true false return def class if elif else try except finally while for\".split())\n",
    "\n",
    "Q_TOKENS = set(\"\"\"\n",
    "x y z h s sdg t tdg rx ry rz rzz rzx rxy sx cx ccx cnot cz swap cswap iswap ecr u u1 u2 u3\n",
    "measure barrier qreg creg backend provider aer terra pulse schedule bind assign_parameters\n",
    "QuantumCircuit QuantumRegister ClassicalRegister Parameter ParameterVector\n",
    "DAGCircuit PassManager layout mapper transpile basis_gates optimization_level qasm dag layout pass\n",
    "CouplingMap AncillaAllocation NoiseModel Calibrations LayoutPass Unroller\n",
    "\"\"\".split())\n",
    "\n",
    "def safe_read(p: Path) -> str:\n",
    "    try: return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def tokenize(s: str): return [w.lower() for w in WORD_RE.findall(s) if w and w.lower() not in STOPWORDS]\n",
    "\n",
    "def changed_lines_in_A(a_text: str, b_text: str) -> set[int]:\n",
    "    a = a_text.splitlines(); b = b_text.splitlines()\n",
    "    sm = difflib.SequenceMatcher(None, a, b, autojunk=False)\n",
    "    touched=set()\n",
    "    for tag,i1,i2,j1,j2 in sm.get_opcodes():\n",
    "        if tag in (\"replace\",\"delete\"): touched.update(range(i1+1, i2+1))\n",
    "    return touched\n",
    "\n",
    "def dcg(scores): return sum(s/ math.log2(i+2) for i,s in enumerate(scores))\n",
    "def ecdf(arr):\n",
    "    arr=np.asarray(arr, float); arr=arr[~np.isnan(arr)]\n",
    "    x=np.sort(arr); y=np.arange(1,len(x)+1)/max(1,len(x)); return x,y\n",
    "\n",
    "# ------------------------------- dataset scan & split -------------------------------\n",
    "def iter_cases(db_root: Path):\n",
    "    for buggy in db_root.rglob(\"buggy.py\"):\n",
    "        d=buggy.parent; fixed=None\n",
    "        for nm in (\"fixed.py\",\"fix.py\"):\n",
    "            p=d/nm\n",
    "            if p.exists(): fixed=p; break\n",
    "        if not fixed: continue\n",
    "        cid=str(d.relative_to(db_root)).replace(os.sep,\"/\")\n",
    "        yield cid, d, Path(buggy), Path(fixed)\n",
    "\n",
    "@dataclass\n",
    "class CodeChunk:\n",
    "    chunk_id: str; repo_key: str; file_path: str\n",
    "    start_line: int; end_line: int; symbol: str; kind: str; text: str\n",
    "\n",
    "class ASTChunker:\n",
    "    def __init__(self, window_fallback=80, window_overlap=10):\n",
    "        self.window_fallback=window_fallback; self.window_overlap=window_overlap\n",
    "    def chunk_file(self, case_dir: Path, file_path: Path, repo_key: str):\n",
    "        rel = str(file_path.relative_to(case_dir))\n",
    "        src = safe_read(file_path); lines = src.splitlines()\n",
    "        try: root = ast.parse(src)\n",
    "        except Exception: root=None\n",
    "        chunks=[]\n",
    "        def add(s,e,sym,kind):\n",
    "            s=max(1,int(s)); e=max(s,int(e))\n",
    "            chunks.append(CodeChunk(md5(f\"{rel}:{s}-{e}\".encode()).hexdigest()[:12],\n",
    "                                    repo_key, rel, s,e, sym, kind, \"\\n\".join(lines[s-1:e])))\n",
    "        if root is not None:\n",
    "            for n in ast.walk(root):\n",
    "                if isinstance(n,(ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                    add(getattr(n,\"lineno\",1), getattr(n,\"end_lineno\",1),\n",
    "                        getattr(n,\"name\",\"<sym>\"),\n",
    "                        \"class\" if isinstance(n,ast.ClassDef) else \"function\")\n",
    "        if not chunks:\n",
    "            step=self.window_fallback-self.window_overlap; i=0; n=len(lines)\n",
    "            while i<n:\n",
    "                s=i+1; e=min(i+self.window_fallback, n); add(s,e,\"<module>\",\"module\"); i+=step\n",
    "        return chunks\n",
    "\n",
    "CALL_RE = re.compile(r\"\\.([A-Za-z_]\\w*)\\s*\\(\")\n",
    "IMPORT_QISKIT_RE  = re.compile(r\"^\\s*(?:from\\s+qiskit(?:\\.[\\w\\.]+)?\\s+import\\s+([\\w\\,\\s]+)|import\\s+qiskit(?:\\.[\\w\\.]+)?(?:\\s+as\\s+(\\w+))?)\", re.M)\n",
    "Q_PIPELINE = [\"QuantumCircuit\",\"DAGCircuit\",\"PassManager\",\"transpile\",\"layout\",\"coupling_map\",\"qasm\",\"basis_gates\",\"Parameter\",\"compose\",\"append\",\"measure\",\"barrier\",\"decompose\",\"reset\",\"initialize\"]\n",
    "\n",
    "def build_hinted_query(seed_q: str, buggy_text: str, kmax=8):\n",
    "    toks = tokenize(buggy_text); freq = Counter(toks)\n",
    "    q_from_tokens = [t for t,_ in freq.most_common() if t in Q_TOKENS]\n",
    "    calls = [m.group(1).lower() for m in CALL_RE.finditer(buggy_text)]\n",
    "    call_counts = Counter([c for c in calls if c in {\"cx\",\"rz\",\"ry\",\"rx\",\"swap\",\"cz\",\"ccx\",\"measure\",\"append\",\"compose\",\"decompose\"}])\n",
    "    present_pipeline = [w.lower() for w in Q_PIPELINE if w.lower() in buggy_text.lower()]\n",
    "    aliases=[]\n",
    "    for m in IMPORT_QISKIT_RE.finditer(buggy_text):\n",
    "        mods, alias = m.groups()\n",
    "        if alias: aliases.append(alias.strip())\n",
    "        if mods:\n",
    "            for name in mods.split(\",\"):\n",
    "                nm=name.strip()\n",
    "                if nm: aliases.append(nm)\n",
    "    merged=[]; \n",
    "    def push(xs):\n",
    "        for x in xs:\n",
    "            x=x.lower()\n",
    "            if x and x not in merged: merged.append(x)\n",
    "    push([g for g,_ in call_counts.most_common()])\n",
    "    push(q_from_tokens); push(present_pipeline); push([a for a in aliases if a!=\"qiskit\"])\n",
    "    if not merged: merged=[\"cx\",\"rz\",\"dag\",\"layout\",\"transpile\",\"qasm\"]\n",
    "    hint_tokens = merged[:kmax]\n",
    "    return (seed_q + \" \" + \" \".join(hint_tokens)).strip(), len(hint_tokens)\n",
    "\n",
    "# BM25\n",
    "class _MiniBM25:\n",
    "    def __init__(self, docs):\n",
    "        self.docs=docs; self.N=len(docs); self.lens=[len(d) for d in docs]\n",
    "        self.avg=sum(self.lens)/max(1,self.N)\n",
    "        df=Counter()\n",
    "        for d in docs: df.update(set(d))\n",
    "        self.df=dict(df)\n",
    "    def idf(self,t):\n",
    "        df=self.df.get(t,0)\n",
    "        return 0.0 if df==0 else math.log(1+(self.N-df+0.5)/(df+0.5))\n",
    "    def score(self, q, doc, dl):\n",
    "        k1,b=1.5,0.75; f=Counter(doc); s=0.0\n",
    "        for t in q:\n",
    "            if t not in self.df: continue\n",
    "            tf=f.get(t,0); \n",
    "            if tf==0: continue\n",
    "            denom=tf+k1*(1-b+b*dl/max(1,self.avg))\n",
    "            s+=self.idf(t)*(tf*(k1+1))/denom\n",
    "        return s\n",
    "\n",
    "class HybridIndex:\n",
    "    def __init__(self, boost_map=None, include_paths=False):\n",
    "        self.boost_map={k.lower():float(v) for k,v in (boost_map or {}).items()}\n",
    "        self.include_paths=include_paths; self.records=[]; self.docs=[]\n",
    "    def build(self, chunks):\n",
    "        self.records=[]; self.docs=[]\n",
    "        for c in chunks:\n",
    "            header=f\"{c.symbol} {c.kind} \"\n",
    "            if self.include_paths: header += c.file_path + \" \"\n",
    "            toks=tokenize(header+\"\\n\"+c.text)\n",
    "            boost=sum(self.boost_map.get(t,0.0) for t in toks)\n",
    "            self.records.append({\"chunk\":c,\"tokens\":toks,\"boost\":float(boost)})\n",
    "            self.docs.append(toks)\n",
    "        self.bm25=_MiniBM25(self.docs)\n",
    "    def search(self, query, topk=10):\n",
    "        q=tokenize(query)\n",
    "        scored=[]\n",
    "        for i,rec in enumerate(self.records):\n",
    "            s=self.bm25.score(q, rec[\"tokens\"], len(rec[\"tokens\"])) + 0.02*rec[\"boost\"]\n",
    "            scored.append((s,i))\n",
    "        scored.sort(reverse=True)\n",
    "        out=[]\n",
    "        for s,i in scored[:topk]:\n",
    "            c=self.records[i][\"chunk\"]\n",
    "            out.append({\"score\":float(s), \"re_score\":0.0, \"file\":c.file_path, \"symbol\":c.symbol, \"kind\":c.kind,\n",
    "                        \"start\":c.start_line, \"end\":c.end_line, \"preview\":\"\\n\".join(c.text.splitlines()[:120])})\n",
    "        return out\n",
    "\n",
    "def quantum_boost_map(alpha=1.8): return {t.lower():alpha for t in Q_TOKENS}\n",
    "\n",
    "# Cross-encoder — honest gating (no phantom “on”)\n",
    "class CrossEncoderReranker:\n",
    "    def __init__(self, model_name):\n",
    "        try:\n",
    "            from sentence_transformers import CrossEncoder\n",
    "            self.model=CrossEncoder(model_name); self.enabled=True\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] CrossEncoder unavailable; 'rerank=on' configs will be skipped.\", e)\n",
    "            self.model=None; self.enabled=False\n",
    "    def score_pairs(self, pairs):\n",
    "        if not self.enabled: raise RuntimeError(\"Reranker disabled\")\n",
    "        import numpy as np\n",
    "        return np.asarray(self.model.predict(pairs), dtype=float)\n",
    "\n",
    "def apply_rerank(query, pool_u, rr):\n",
    "    pairs=[(query, h.get(\"preview\",\"\")) for h in pool_u]\n",
    "    scores=rr.score_pairs(pairs)\n",
    "    for h,s in zip(pool_u, scores): h[\"re_score\"]=float(s)\n",
    "    return sorted(pool_u, key=lambda r: r.get(\"re_score\",0.0), reverse=True)\n",
    "\n",
    "# priors, selectors, diagnostics helpers\n",
    "def syntax_prior_of(hit):\n",
    "    txt=(hit.get(\"preview\",\"\")+\" \"+hit.get(\"symbol\",\"\")).lower()\n",
    "    prior=0.0\n",
    "    if any(t in txt for t in [\"assert\",\"raise\",\"error\",\"exception\"]): prior+=0.10\n",
    "    if any(t in txt for t in [\"dag\",\"layout\",\"transpile\",\"qasm\",\"coupling_map\",\"basis_gates\"]): prior+=0.12\n",
    "    if any(t.lower() in txt for t in Q_TOKENS): prior+=0.10\n",
    "    if re.search(r'\\b(run|apply)\\b', txt): prior+=0.08\n",
    "    return min(prior,0.6)\n",
    "\n",
    "def apply_syntax_prior(pool_u, alpha=0.5):\n",
    "    out=[]\n",
    "    for h in pool_u:\n",
    "        sp=syntax_prior_of(h); base=h.get(\"re_score\", h.get(\"score\",0.0))\n",
    "        g=dict(h); g[\"syn_prior\"]=sp; g[\"score\"]=base*(1.0+alpha*sp); out.append(g)\n",
    "    return sorted(out, key=lambda r:r[\"score\"], reverse=True)\n",
    "\n",
    "def select_by_coverage_balanced(pool_u, topk, w_gain=0.8, w_base=1.0, w_rerank=1.5,\n",
    "                                w_div_file=0.15, w_div_sym=0.10, pen_overlap=0.10):\n",
    "    sel,covered=[],set(); seen_files,set_syms=set(),set()\n",
    "    base=np.array([h.get(\"score\",0.0) for h in pool_u], float)\n",
    "    bn=(base-base.min())/(base.max()-base.min()+1e-9)\n",
    "    rn=np.array([h.get(\"re_score\",0.0) for h in pool_u], float)\n",
    "    for h,b,r in zip(pool_u,bn,rn): h[\"_bn\"]=float(b); h[\"_rn\"]=float(r)\n",
    "    for _ in range(min(topk,len(pool_u))):\n",
    "        best,best_s=None,-1e9\n",
    "        for h in pool_u:\n",
    "            if h in sel: continue\n",
    "            rng=set(range(h[\"start\"],h[\"end\"]+1)); size=max(1,h[\"end\"]-h[\"start\"]+1)\n",
    "            gain=len(rng-covered); gain_norm=gain/size; overlap=1.0-gain_norm\n",
    "            s=w_gain*gain_norm + w_base*h[\"_bn\"] + w_rerank*h[\"_rn\"]\n",
    "            s += (w_div_file if h[\"file\"] not in seen_files else 0.0)\n",
    "            s += (w_div_sym  if h[\"symbol\"] not in set_syms else 0.0)\n",
    "            s -= pen_overlap*overlap\n",
    "            if s>best_s: best,best_s=h,s\n",
    "        if best is None: break\n",
    "        sel.append(best); covered|=set(range(best[\"start\"],best[\"end\"]+1))\n",
    "        seen_files.add(best[\"file\"]); set_syms.add(best[\"symbol\"])\n",
    "    return sel\n",
    "\n",
    "def select_by_coverage_old(hits, topk, w_new_file=10.0, w_new_symbol=6.0, w_rerank=2.0):\n",
    "    selected, covered=[], set(); seen_files,seen_syms=set(),set()\n",
    "    for _ in range(min(topk,len(hits))):\n",
    "        best,score=None,-1.0\n",
    "        for h in hits:\n",
    "            if h in selected: continue\n",
    "            rng=set(range(h[\"start\"],h[\"end\"]+1)); gain=len(rng-covered)\n",
    "            tie=h.get(\"re_score\",h.get(\"score\",0.0))\n",
    "            s=gain + (w_new_file if h[\"file\"] not in seen_files else 0.0) \\\n",
    "                    + (w_new_symbol if h[\"symbol\"] not in seen_syms else 0.0) \\\n",
    "                    + (w_rerank*tie)\n",
    "            if s>score: best,score=h,s\n",
    "        if best is None: break\n",
    "        selected.append(best); covered|=set(range(best[\"start\"],best[\"end\"]+1))\n",
    "        seen_files.add(best[\"file\"]); seen_syms.add(best[\"symbol\"])\n",
    "    return selected\n",
    "\n",
    "def _kendall_tau(keys_a, keys_b):\n",
    "    n=min(len(keys_a), len(keys_b), 25)\n",
    "    if n<3: return np.nan\n",
    "    a=keys_a[:n]; b=keys_b[:n]; pos={k:i for i,k in enumerate(b)}\n",
    "    conc=disc=0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            ki,kj=a[i],a[j]\n",
    "            if ki not in pos or kj not in pos: continue\n",
    "            conc += int(pos[ki] < pos[kj]); disc += int(pos[ki] > pos[kj])\n",
    "    denom=conc+disc\n",
    "    return (conc-disc)/denom if denom>0 else np.nan\n",
    "\n",
    "def _quantum_density(texts):\n",
    "    toks=[]; qcnt=0\n",
    "    for t in texts:\n",
    "        ts=tokenize(t); toks.extend(ts); qcnt += sum(1 for z in ts if z in Q_TOKENS)\n",
    "    total=max(1,len(toks)); return qcnt, qcnt/total\n",
    "\n",
    "# ------------------------------- build chunks & meta -------------------------------\n",
    "chunker=ASTChunker()\n",
    "all_chunks_ast, all_chunks_win, meta=[],[],{}\n",
    "for cid,case_dir,bug_f,fix_f in iter_cases(DB_ROOT):\n",
    "    for ch in chunker.chunk_file(case_dir, bug_f, repo_key=cid):\n",
    "        ch.file_path=f\"{cid}/{ch.file_path}\"; all_chunks_ast.append(ch)\n",
    "    txt=safe_read(bug_f); lines=txt.splitlines()\n",
    "    win,overlap=80,10; step=max(1,win-overlap); i=0\n",
    "    while i<len(lines):\n",
    "        s=i+1; e=min(i+win,len(lines))\n",
    "        all_chunks_win.append(CodeChunk(md5(f\"{cid}/{bug_f.name}:{s}-{e}\".encode()).hexdigest()[:12],\n",
    "                                        cid, f\"{cid}/{bug_f.name}\", s,e, f\"<win@{s}-{e}>\",\"module\",\"\\n\".join(lines[s-1:e])))\n",
    "        i+=step\n",
    "    meta[cid]={\"gold\":changed_lines_in_A(txt, safe_read(fix_f)), \"query\": \" \".join(tokenize(txt)[:6]),\n",
    "               \"project\": cid.split(\"/\")[0], \"bug_text\": txt}\n",
    "\n",
    "# stable 70/25/5 split\n",
    "ALL = sorted(meta.keys(), key=lambda k: md5(k.encode()).hexdigest())\n",
    "n=len(ALL); n_train=int(round(0.70*n)); n_val=int(round(0.25*n))\n",
    "TRAIN, VAL, TEST = ALL[:n_train], ALL[n_train:n_train+n_val], ALL[n_train+n_val:]\n",
    "json.dump({\"train\":TRAIN,\"val\":VAL,\"test\":TEST,\"n\":n}, open(SAVE/\"splits_70_25_5.json\",\"w\"), indent=2)\n",
    "k_train = max(1, int(math.ceil(len(TRAIN)*DATA_PERCENT/100.0))); TRAIN_SUB=TRAIN[:k_train]\n",
    "print(f\"[SPLIT] train={len(TRAIN)} val={len(VAL)} test={len(TEST)} ; grid uses TRAIN_SUB={len(TRAIN_SUB)}\")\n",
    "\n",
    "# ------------------------------- indices -------------------------------\n",
    "def build_index(chunks, use_boost=False):\n",
    "    boost=quantum_boost_map(1.8) if use_boost else {}\n",
    "    idx=HybridIndex(boost_map=boost, include_paths=False); idx.build(chunks); return idx\n",
    "\n",
    "def _keep_cases(chunks, subset):\n",
    "    keep=set(subset); return [c for c in chunks if str(c.repo_key) in keep]\n",
    "\n",
    "if INDEX_SCOPE_FOR_ABLATION==\"train\":\n",
    "    chunks_ast_TR=_keep_cases(all_chunks_ast, TRAIN_SUB)\n",
    "    chunks_win_TR=_keep_cases(all_chunks_win, TRAIN_SUB)\n",
    "else:\n",
    "    chunks_ast_TR=all_chunks_ast; chunks_win_TR=all_chunks_win\n",
    "\n",
    "# train-scope indices (for selection)\n",
    "idx_ast_base_TR   = build_index(chunks_ast_TR,  use_boost=False)\n",
    "idx_ast_q_TR      = build_index(chunks_ast_TR,  use_boost=True)\n",
    "idx_win_base_TR   = build_index(chunks_win_TR,  use_boost=False)\n",
    "idx_win_q_TR      = build_index(chunks_win_TR,  use_boost=True)\n",
    "\n",
    "# all-scope indices (for reporting best cfg across splits)\n",
    "idx_ast_base_ALL  = build_index(all_chunks_ast, use_boost=False)\n",
    "idx_ast_q_ALL     = build_index(all_chunks_ast, use_boost=True)\n",
    "idx_win_base_ALL  = build_index(all_chunks_win, use_boost=False)\n",
    "idx_win_q_ALL     = build_index(all_chunks_win, use_boost=True)\n",
    "\n",
    "# ------------------------------- evaluation core (with diagnostics) -------------------------------\n",
    "def eval_config(index, cases, use_hints, use_reranker, selector, use_syntax, name_for_tqdm=\"cfg\"):\n",
    "    rr = CrossEncoderReranker(RERANK_MODEL) if use_reranker else None\n",
    "    if use_reranker and not rr.enabled:\n",
    "        return pd.DataFrame()  # skip 'on' if model missing\n",
    "\n",
    "    select_fn = select_by_coverage_old if selector==\"old\" else select_by_coverage_balanced\n",
    "    rows=[]\n",
    "    for cid in tqdm(cases, desc=f\"[{name_for_tqdm}] cases\", leave=False):\n",
    "        gold = meta[cid][\"gold\"]; seed_q = meta[cid][\"query\"]; bug_txt=meta[cid][\"bug_text\"]\n",
    "\n",
    "        q, hint_count = (build_hinted_query(seed_q, bug_txt) if use_hints else (seed_q, 0))\n",
    "        query_len = len(tokenize(q))\n",
    "\n",
    "        pool = index.search(q, topk=max(OVERRETRIEVE, 6*TOPK))\n",
    "        seen=set(); pool_u=[]\n",
    "        for h in pool:\n",
    "            key=(h[\"file\"],h[\"start\"],h[\"end\"])\n",
    "            if key in seen: continue\n",
    "            seen.add(key); pool_u.append(h)\n",
    "\n",
    "        base_sorted = sorted(pool_u, key=lambda r:r.get(\"score\",0.0), reverse=True)\n",
    "        base_keys   = [(h[\"file\"],h[\"start\"],h[\"end\"]) for h in base_sorted]\n",
    "\n",
    "        # rerank (diagnostics)\n",
    "        if rr is not None:\n",
    "            pool_rr = apply_rerank(q, pool_u, rr)\n",
    "            rr_keys = [(h[\"file\"],h[\"start\"],h[\"end\"]) for h in pool_rr]\n",
    "            top_shift = 1.0 if (base_keys[:1] != rr_keys[:1]) else 0.0\n",
    "            kendall25 = _kendall_tau(base_keys, rr_keys)\n",
    "            n = min(50, len(pool_rr))\n",
    "            base_scores = [h.get(\"score\",0.0) for h in pool_rr[:n]]\n",
    "            re_scores   = [h.get(\"re_score\",0.0) for h in pool_rr[:n]]\n",
    "            if n>=3 and np.std(base_scores)>0 and np.std(re_scores)>0:\n",
    "                spearman = np.corrcoef(np.argsort(np.argsort(base_scores)),\n",
    "                                       np.argsort(np.argsort(re_scores)))[0,1]\n",
    "            else:\n",
    "                spearman = np.nan\n",
    "        else:\n",
    "            pool_rr = pool_u; top_shift=np.nan; kendall25=np.nan; spearman=np.nan\n",
    "\n",
    "        pool_for_sel = apply_syntax_prior(pool_rr, alpha=0.5) if use_syntax else pool_rr\n",
    "        select_fn_use = select_by_coverage_old if selector==\"old\" else select_by_coverage_balanced\n",
    "        selected = select_fn_use(pool_for_sel, TOPK)\n",
    "\n",
    "        # graded relevance + diagnostics\n",
    "        rel, same_scores, covered = [], [], set()\n",
    "        uniq_files=set(); uniq_syms=set(); span_lens=[]\n",
    "        synpriors=[]; previews=[]\n",
    "        for h in selected:\n",
    "            span=max(1, h[\"end\"]-h[\"start\"]+1); span_lens.append(span)\n",
    "            uniq_files.add(h[\"file\"]); uniq_syms.add(h[\"symbol\"])\n",
    "            previews.append(h.get(\"preview\",\"\")); synpriors.append(syntax_prior_of(h))\n",
    "            same_case = h[\"file\"].startswith(cid + \"/\")\n",
    "            overlap = sum(1 for ln in gold if h[\"start\"]<=ln<=h[\"end\"])\n",
    "            frac = overlap/span\n",
    "            rel.append(frac if same_case else 0.0)\n",
    "            if same_case:\n",
    "                same_scores.append(frac); covered.update(range(h[\"start\"],h[\"end\"]+1))\n",
    "\n",
    "        hit = 1.0 if any(x>0 for x in rel) else 0.0\n",
    "        try: rk = next(i+1 for i,x in enumerate(rel) if x>0); mrr = 1.0/rk\n",
    "        except StopIteration: mrr=0.0\n",
    "        ideal = dcg(sorted(rel, reverse=True)); ndcg = (dcg(rel)/ideal) if ideal>0 else 0.0\n",
    "        line_recall = len({ln for ln in covered if ln in gold}) / max(1,len(gold))\n",
    "        prec_proxy = float(np.mean(same_scores)) if same_scores else 0.0\n",
    "\n",
    "        q_cnt, q_density = _quantum_density(previews)\n",
    "        synprior_mean = float(np.mean(synpriors)) if synpriors else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"case\":cid,\n",
    "            # base metrics\n",
    "            \"Hit@K_global\":hit, \"MRR_line_global\":mrr, \"nDCG@K_global\":ndcg,\n",
    "            \"LineRecall@K\":line_recall, \"WindowPrecProxy\":prec_proxy,\n",
    "            # extras for your plots\n",
    "            \"Hit@1\": 1.0 if len(rel)>=1 and rel[0]>0 else 0.0,\n",
    "            \"Hit@2\": 1.0 if (len(rel)>=2 and (rel[0]>0 or rel[1]>0)) else (1.0 if len(rel)>=1 and rel[0]>0 else 0.0),\n",
    "            \"MeanRank_ifHit\": (1.0/mrr) if mrr>0 else np.nan,\n",
    "            \"SpanOverlap@K\": float(np.mean(rel)) if rel else 0.0,\n",
    "            \"UniqueFiles@K\": len(uniq_files), \"UniqueSymbols@K\": len(uniq_syms),\n",
    "            \"AvgSpanLen@K\": float(np.mean(span_lens)) if span_lens else 0.0,\n",
    "            # rerank diagnostics\n",
    "            \"ReRankSpearman\": spearman,\n",
    "            \"TopShift@Pool\": top_shift,\n",
    "            \"ReRankKendallTop25\": kendall25,\n",
    "            # hint/syntax diagnostics\n",
    "            \"QueryLen\": query_len,\n",
    "            \"HintTokensAppended\": hint_count,\n",
    "            \"QuantumTokensInSelected\": q_cnt,\n",
    "            \"QuantumDensitySelected\": q_density,\n",
    "            \"SynPriorMeanSel\": synprior_mean,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ------------------------------- grid (TRAIN-only) -------------------------------\n",
    "def build_grid(idx_ast, idx_ast_q, idx_win, idx_win_q):\n",
    "    cfgs=[]\n",
    "    for chunking, idx in [(\"AST_base\", idx_ast), (\"AST_q\", idx_ast_q), (\"WIN_base\", idx_win), (\"WIN_q\", idx_win_q)]:\n",
    "        for hints in [False, True]:\n",
    "            for selector in [\"old\",\"balanced\"]:\n",
    "                for rerank in [False, True]:\n",
    "                    for syntax_on in [False, True]:\n",
    "                        cfgs.append((f\"{chunking}__{'hint' if hints else 'nohint'}__{selector}__{'rerank' if rerank else 'noR'}__{'syntax' if syntax_on else 'nosyntax'}\",\n",
    "                                     idx, hints, rerank, selector, syntax_on))\n",
    "    return cfgs\n",
    "\n",
    "# indices used for selection (train-scoped)\n",
    "idxs_TR = {\n",
    "    \"AST_base\": idx_ast_base_TR, \"AST_q\": idx_ast_q_TR,\n",
    "    \"WIN_base\": idx_win_base_TR, \"WIN_q\": idx_win_q_TR\n",
    "}\n",
    "\n",
    "df_list=[]\n",
    "for name, idx, hints, rerank, selector, syntax_on in tqdm(build_grid(**{\n",
    "    \"idx_ast\": idxs_TR[\"AST_base\"],\n",
    "    \"idx_ast_q\": idxs_TR[\"AST_q\"],\n",
    "    \"idx_win\": idxs_TR[\"WIN_base\"],\n",
    "    \"idx_win_q\": idxs_TR[\"WIN_q\"]\n",
    "}), desc=\"[Ablation|TRAIN] configs\"):\n",
    "    dfc = eval_config(idx, TRAIN_SUB, use_hints=hints, use_reranker=rerank, selector=selector, use_syntax=syntax_on, name_for_tqdm=name)\n",
    "    if dfc.empty:  # reranker gated off\n",
    "        continue\n",
    "    dfc[\"config\"]=name; df_list.append(dfc)\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "df_all.to_csv(SAVE/\"ablation_all_raw.csv\", index=False)\n",
    "\n",
    "# ------------------------------- aggregations (TRAIN) -------------------------------\n",
    "base_metrics  = [\"Hit@K_global\",\"MRR_line_global\",\"nDCG@K_global\",\"LineRecall@K\",\"WindowPrecProxy\"]\n",
    "extra_metrics = [\"Hit@1\",\"Hit@2\",\"MeanRank_ifHit\",\"SpanOverlap@K\",\"UniqueFiles@K\",\"UniqueSymbols@K\",\"AvgSpanLen@K\"]\n",
    "diag_metrics  = [\"ReRankSpearman\",\"TopShift@Pool\",\"ReRankKendallTop25\",\"QueryLen\",\"HintTokensAppended\",\"QuantumTokensInSelected\",\"QuantumDensitySelected\",\"SynPriorMeanSel\"]\n",
    "\n",
    "macro     = df_all.groupby(\"config\")[base_metrics+extra_metrics].mean().sort_index()\n",
    "diag_macro= df_all.groupby(\"config\")[diag_metrics].mean().sort_index()\n",
    "macro.to_csv(SAVE/\"ablation_macro_means.csv\")\n",
    "diag_macro.to_csv(SAVE/\"ablation_diag_macro_means.csv\")\n",
    "\n",
    "baseline = \"AST_base__nohint__old__noR__nosyntax\"\n",
    "if baseline not in macro.index: baseline = macro.index[0]\n",
    "best_cfg = macro[\"nDCG@K_global\"].idxmax()\n",
    "(SAVE/\"best_config.txt\").write_text(best_cfg+\"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "delta = (macro - macro.loc[baseline]).drop(index=baseline)\n",
    "delta.to_csv(SAVE/\"ablation_delta_vs_baseline.csv\")\n",
    "\n",
    "# ------------------------------- plots (exactly like before) -------------------------------\n",
    "def savefig(path): Path(path).parent.mkdir(parents=True, exist_ok=True); plt.tight_layout(); plt.savefig(path); plt.close()\n",
    "\n",
    "# heatmaps\n",
    "plt.figure(figsize=(min(22, 2+0.24*len(macro.index)), 10))\n",
    "im=plt.imshow(macro[base_metrics].values, aspect=\"auto\", vmin=0, vmax=1, cmap=\"viridis\")\n",
    "plt.colorbar(im, fraction=0.02, pad=0.02).set_label(\"macro mean\")\n",
    "plt.yticks(range(len(macro.index)), macro.index, fontsize=7)\n",
    "plt.xticks(range(len(base_metrics)), base_metrics, rotation=25, ha=\"right\")\n",
    "plt.title(\"Ablation: macro means (base metrics)\")\n",
    "savefig(SAVE/\"abl_macro_heatmap.png\")\n",
    "\n",
    "plt.figure(figsize=(min(22, 2+0.24*len(macro.index)), 10))\n",
    "im=plt.imshow(macro[extra_metrics].replace([np.inf,-np.inf],np.nan).fillna(0.0).values, aspect=\"auto\", cmap=\"magma\")\n",
    "plt.colorbar(im, fraction=0.02, pad=0.02).set_label(\"macro mean\")\n",
    "plt.yticks(range(len(macro.index)), macro.index, fontsize=7)\n",
    "plt.xticks(range(len(extra_metrics)), extra_metrics, rotation=25, ha=\"right\")\n",
    "plt.title(\"Ablation: macro means (extra metrics)\")\n",
    "savefig(SAVE/\"abl_macro_heatmap_extra.png\")\n",
    "\n",
    "plt.figure(figsize=(min(22, 2+0.24*len(delta.index)), 10))\n",
    "v=np.nanmax(np.abs(delta[base_metrics].values)); im=plt.imshow(delta[base_metrics].values, aspect=\"auto\", vmin=-v, vmax=+v, cmap=\"coolwarm\")\n",
    "plt.colorbar(im, fraction=0.02, pad=0.02).set_label(f\"Δ vs {baseline}\")\n",
    "plt.yticks(range(len(delta.index)), delta.index, fontsize=7)\n",
    "plt.xticks(range(len(base_metrics)), base_metrics, rotation=25, ha=\"right\")\n",
    "plt.title(f\"Ablation: Δ vs baseline ({baseline})\")\n",
    "savefig(SAVE/\"abl_delta_heatmap.png\")\n",
    "\n",
    "subset = [f\"AST_base__nohint__{sel}__{rr}__{sx}\" for sel in [\"old\",\"balanced\"] for rr in [\"noR\",\"rerank\"] for sx in [\"nosyntax\",\"syntax\"]] + \\\n",
    "         [f\"AST_q__hint__{sel}__{rr}__{sx}\"      for sel in [\"old\",\"balanced\"] for rr in [\"noR\",\"rerank\"] for sx in [\"nosyntax\",\"syntax\"]]\n",
    "subset=[c for c in subset if c in macro.index]\n",
    "plt.figure(figsize=(14,6))\n",
    "x=np.arange(len(base_metrics)); w=0.06\n",
    "for i,cfg in enumerate(subset):\n",
    "    plt.bar(x+i*w, macro.loc[cfg, base_metrics].values, width=w, label=cfg)\n",
    "plt.xticks(x+(len(subset)-1)*w/2, base_metrics, rotation=20, ha=\"right\")\n",
    "plt.ylabel(\"macro mean\"); plt.title(\"Readable subset: AST only (base metrics)\")\n",
    "plt.legend(fontsize=7, ncol=3)\n",
    "savefig(SAVE/\"abl_ast_subset_bars.png\")\n",
    "\n",
    "# main effects (base)\n",
    "def mean_by_factor(df_all, factor_fn):\n",
    "    tmp=df_all.copy(); tmp[\"factor\"]=tmp[\"config\"].map(factor_fn)\n",
    "    return tmp.groupby(\"factor\")[base_metrics].mean()\n",
    "\n",
    "effects = {\n",
    "    \"selector\": mean_by_factor(df_all, lambda c: \"old\" if \"__old__\" in c else \"balanced\"),\n",
    "    \"reranker\": mean_by_factor(df_all, lambda c: \"on\" if \"__rerank__\" in c else \"off\"),\n",
    "    \"hints\":    mean_by_factor(df_all, lambda c: \"hint\" if \"__hint__\" in c else \"nohint\"),\n",
    "    \"boost\":    mean_by_factor(df_all, lambda c: \"boost\" if c.startswith(\"AST_q\") or c.startswith(\"WIN_q\") else \"noboost\"),\n",
    "    \"chunking\": mean_by_factor(df_all, lambda c: \"AST\" if c.startswith(\"AST_\") else \"WIN\"),\n",
    "    \"syntax\":   mean_by_factor(df_all, lambda c: \"syntax\" if c.endswith(\"__syntax\") else \"nosyntax\"),\n",
    "}\n",
    "for name, dfm in effects.items():\n",
    "    plt.figure(figsize=(7.5,4))\n",
    "    for j,m in enumerate(base_metrics):\n",
    "        plt.bar(np.arange(len(dfm.index))+j*0.18, dfm[m].values, width=0.18, label=m)\n",
    "    plt.xticks(np.arange(len(dfm.index))+0.36, dfm.index)\n",
    "    plt.ylabel(\"macro mean\"); plt.title(f\"Main effect: {name} (base metrics)\")\n",
    "    plt.legend(fontsize=7, ncol=3)\n",
    "    savefig(SAVE/f\"abl_main_effect_{name}.png\")\n",
    "    dfm.to_csv(SAVE/f\"main_effect_{name}.csv\")\n",
    "\n",
    "# ECDF baseline vs best (TRAIN)\n",
    "for metric in [\"MRR_line_global\",\"nDCG@K_global\"]:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    xs, ys = ecdf(df_all.loc[df_all[\"config\"]==baseline, metric].values); plt.plot(xs, ys, label=baseline)\n",
    "    xs, ys = ecdf(df_all.loc[df_all[\"config\"]==best_cfg, metric].values); plt.plot(xs, ys, label=best_cfg)\n",
    "    plt.xlabel(metric); plt.ylabel(\"ECDF\"); plt.title(f\"ECDF — baseline vs best ({best_cfg})\")\n",
    "    plt.legend(fontsize=7); savefig(SAVE/f\"abl_ecdf_{metric}_baseline_vs_best.png\")\n",
    "\n",
    "def _bucket_mrr(mrr):\n",
    "    if mrr <= 0 or np.isnan(mrr): return \"Miss\"\n",
    "    r=int(round(1.0/mrr))\n",
    "    return \"Top-1\" if r<=1 else \"Top-2\" if r==2 else \"Top-3\" if r==3 else \"Top-4+\"\n",
    "def _rank_breakdown(df, cfg):\n",
    "    b=pd.Series([_bucket_mrr(x) for x in df.loc[df[\"config\"]==cfg, \"MRR_line_global\"]]).value_counts(normalize=True)\n",
    "    return b.reindex([\"Top-1\",\"Top-2\",\"Top-3\",\"Top-4+\",\"Miss\"]).fillna(0.0)\n",
    "rb_base=_rank_breakdown(df_all, baseline); rb_best=_rank_breakdown(df_all, best_cfg)\n",
    "plt.figure(figsize=(7,4))\n",
    "bottom=np.zeros(2); labels=[\"Top-1\",\"Top-2\",\"Top-3\",\"Top-4+\",\"Miss\"]\n",
    "for lab in labels:\n",
    "    vals=[rb_base[lab], rb_best[lab]]\n",
    "    plt.bar([\"baseline\",\"best\"], vals, bottom=bottom, label=lab); bottom += vals\n",
    "plt.ylabel(\"share\"); plt.title(f\"Rank breakdown — baseline vs best ({best_cfg})\")\n",
    "plt.legend(ncol=5, fontsize=7); savefig(SAVE/\"abl_rank_breakdown_baseline_vs_best.png\")\n",
    "\n",
    "# diagnostics heatmap (z-scored) + hints diagnostics main-effect\n",
    "diag_z = (diag_macro - diag_macro.mean())/diag_macro.std(ddof=0)\n",
    "plt.figure(figsize=(min(22, 2+0.24*len(diag_z.index)), 10))\n",
    "im=plt.imshow(diag_z[diag_metrics].fillna(0.0).values, aspect=\"auto\", cmap=\"coolwarm\")\n",
    "plt.colorbar(im, fraction=0.02, pad=0.02).set_label(\"z-score\")\n",
    "plt.yticks(range(len(diag_z.index)), diag_z.index, fontsize=7)\n",
    "plt.xticks(range(len(diag_metrics)), diag_metrics, rotation=25, ha=\"right\")\n",
    "plt.title(\"Ablation diagnostics (z-scored)\")\n",
    "savefig(SAVE/\"abl_diag_heatmap_z.png\")\n",
    "\n",
    "tmp=df_all.copy(); tmp[\"factor\"]=tmp[\"config\"].map(lambda c: \"hint\" if \"__hint__\" in c else \"nohint\")\n",
    "hints_diag = tmp.groupby(\"factor\")[diag_metrics].mean()\n",
    "plt.figure(figsize=(10,4))\n",
    "for j,m in enumerate(diag_metrics):\n",
    "    plt.bar(np.arange(len(hints_diag.index))+j*0.1, hints_diag[m].values, width=0.1, label=m)\n",
    "plt.xticks(np.arange(len(hints_diag.index))+0.35, hints_diag.index)\n",
    "plt.ylabel(\"mean\"); plt.title(\"Main effect: hints (diagnostics)\")\n",
    "plt.legend(fontsize=7, ncol=3)\n",
    "savefig(SAVE/\"abl_main_effect_hints_diag.png\")\n",
    "\n",
    "# best-config scatters\n",
    "best_rows = df_all[df_all[\"config\"]==best_cfg]\n",
    "if not best_rows.empty:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(best_rows[\"SynPriorMeanSel\"], best_rows[\"WindowPrecProxy\"])\n",
    "    plt.xlabel(\"SynPriorMeanSel\"); plt.ylabel(\"WindowPrecProxy\")\n",
    "    plt.title(\"Syntax prior vs precision proxy (best config)\")\n",
    "    savefig(SAVE/\"scatter_synprior_vs_precproxy_best.png\")\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(best_rows[\"QuantumDensitySelected\"], best_rows[\"nDCG@K_global\"])\n",
    "    plt.xlabel(\"QuantumDensitySelected\"); plt.ylabel(\"nDCG@K_global\")\n",
    "    plt.title(\"Quantum density vs retrieval nDCG (best config)\")\n",
    "    savefig(SAVE/\"scatter_qdensity_vs_ndcg_best.png\")\n",
    "\n",
    "# ------------------------------- best cfg across splits (reporting) -------------------------------\n",
    "def idx_from_name(name: str):\n",
    "    head=name.split(\"__\")[0]\n",
    "    return {\"AST_base\": idx_ast_base_ALL, \"AST_q\": idx_ast_q_ALL, \"WIN_base\": idx_win_base_ALL, \"WIN_q\": idx_win_q_ALL}[head]\n",
    "def parse_cfg(name: str):\n",
    "    p=name.split(\"__\"); return {\"hints\":p[1]==\"hint\",\"selector\":p[2],\"rerank\":p[3]==\"rerank\",\"syntax\":p[4]==\"syntax\"}\n",
    "\n",
    "cfg=parse_cfg(best_cfg); idx_best=idx_from_name(best_cfg)\n",
    "rows=[]\n",
    "for split, CASES in [(\"TRAIN\", TRAIN), (\"VAL\", VAL), (\"TEST\", TEST)]:\n",
    "    df = eval_config(idx_best, CASES, use_hints=cfg[\"hints\"], use_reranker=cfg[\"rerank\"], selector=cfg[\"selector\"], use_syntax=cfg[\"syntax\"], name_for_tqdm=f\"best|{split}\")\n",
    "    m  = df[base_metrics].mean()\n",
    "    rows.append({\"split\":split, **{k:float(m.get(k,np.nan)) for k in m.index}})\n",
    "    df.to_csv(SAVE/f\"percase__{split}.csv\", index=False)\n",
    "pd.DataFrame(rows).set_index(\"split\").to_csv(SAVE/\"macro_by_split.csv\")\n",
    "\n",
    "print(\"\\nArtifacts saved to:\", SAVE.resolve())\n",
    "print(\"Best config (picked on TRAIN only):\", best_cfg)\n",
    "print(\"Index scope for ablation:\", INDEX_SCOPE_FOR_ABLATION, \"| reranker on-configs are skipped if model missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dbe677",
   "metadata": {},
   "source": [
    "# GRAP-Q Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1934f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Split -> train=33 | val=12 | test=2\n",
      "Validation cases usable: 12 (DATA_PERCENT=100)\n",
      "BEST_CONFIG (from file): WIN_base__hint__balanced__rerank__nosyntax (expect this to be TRAIN-only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GRAP-Q|VAL] cases: 100%|██████████| 12/12 [32:04<00:00, 160.37s/it]\n",
      "[Pure-LLM|VAL] cases: 100%|██████████| 12/12 [07:57<00:00, 39.81s/it]\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_16840\\812416284.py:878: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([eff_g.dropna(), eff_l.dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_16840\\812416284.py:908: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([pd.to_numeric(df_grap[\"lines_p\"], errors=\"coerce\").dropna(),\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_16840\\812416284.py:912: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([pd.to_numeric(df_grap[\"lines_r\"], errors=\"coerce\").dropna(),\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_16840\\812416284.py:938: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([pd.to_numeric(df_grap[\"drift\"], errors=\"coerce\").dropna(),\n",
      "C:\\Users\\Alberto\\AppData\\Local\\Temp\\ipykernel_16840\\812416284.py:942: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([pd.to_numeric(df_grap[\"id_jacc\"], errors=\"coerce\").dropna(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION comparison artifacts saved to: C:\\Users\\Alberto\\Desktop\\Quantum\\LAST\\results\\grap_vs_llm_deep\n",
      "BEST_CONFIG used: WIN_base__hint__balanced__rerank__nosyntax\n",
      "Donor policy -> TRAIN only: True | exclude donor-changed windows: True\n"
     ]
    }
   ],
   "source": [
    "# %% FULL PIPELINE — GRAP-Q vs Pure-LLM (Validation-only, Leak-free 70/25/5 split)\n",
    "# Evaluates GRAP-Q agent vs Pure-LLM on the *validation* set only.\n",
    "# Leak-free donor policy:\n",
    "#   • Retrieval index is built from buggy.py for all cases (no labels used).\n",
    "#   • Cross-case donor windows are allowed ONLY from TRAIN cases.\n",
    "#   • Optional donor filter excludes TRAIN donor windows overlapping their own gold changes.\n",
    "#\n",
    "# Artifacts:\n",
    "#   results/grap_vs_llm_deep/\n",
    "#       ├─ splits_70_25_5.json\n",
    "#       ├─ grap_results_val.csv\n",
    "#       ├─ llm_results_val.csv\n",
    "#       ├─ combined_results_val.csv\n",
    "#       ├─ grap_logs_val.json\n",
    "#       ├─ llm_logs_val.json\n",
    "#       ├─ (all plots)*.png   # validation-only\n",
    "#\n",
    "# Requirements:\n",
    "#   - Bugs4Q at data/bugs4q/Bugs4Q-Database/**/buggy.py + fixed.py|fix.py\n",
    "#   - Ollama available (HTTP or CLI fallback)\n",
    "#   - pip: pandas numpy matplotlib sentence-transformers requests tqdm pytest\n",
    "\n",
    "%pip install -q pandas numpy matplotlib sentence-transformers requests tqdm\n",
    "\n",
    "import os, re, json, math, difflib, shutil, subprocess, sys, ast, random, traceback\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from hashlib import md5\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------- USER KNOBS -------------------------------\n",
    "DATA_PERCENT     = 100   # MUST be 1 or 100 (applied after split, to VAL only)\n",
    "BEST_CONFIG_PATH = \"results/qeval_ablation_plus/best_config.txt\"  # <- train-only best config recommended\n",
    "\n",
    "# Donor policy knobs (leak-free):\n",
    "ALLOW_TRAIN_DONORS            = True    # allow cross-case donors only from TRAIN\n",
    "EXCLUDE_TRAIN_DONOR_CHANGED   = True    # exclude TRAIN donors whose window overlaps their own gold-changed lines\n",
    "\n",
    "# ------------------------------- PATHS / CONFIG -------------------------------\n",
    "DB_ROOT   = Path(\"data/bugs4q/Bugs4Q-Database\")\n",
    "OUT_DIR   = Path(\"results/grap_vs_llm_deep\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WORK_DIR  = Path(\".work/grap_vs_llm_deep\");   WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Retrieval / selection\n",
    "TOPK             = 2\n",
    "OVERRETRIEVE     = 80\n",
    "RERANK_MODEL     = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "# LLM (Ollama) for the agent run\n",
    "OLLAMA_URL      = os.environ.get(\"OLLAMA_BASE_URL\", \"http://localhost:11434\").rstrip(\"/\")\n",
    "MODEL_REWRITE   = os.environ.get(\"OLLAMA_MODEL_REWRITE\", \"llama3.1:8b\")\n",
    "MODEL_PATCH     = os.environ.get(\"OLLAMA_MODEL_PATCH\",   \"qwen2.5-coder:14b-instruct\")\n",
    "REW_FALLBACKS   = [\"llama3.1:8b\", \"mistral:7b-instruct\"]\n",
    "PATCH_FALLBACKS = [\"qwen2.5-coder:14b-instruct\",\"qwen2.5-coder:7b-instruct\",\"deepseek-coder:6.7b-instruct\",\"mistral:7b-instruct\"]\n",
    "NUM_CTX_REWRITE = int(os.environ.get(\"NUM_CTX_REWRITE\", \"8192\"))\n",
    "NUM_CTX_PATCH   = int(os.environ.get(\"NUM_CTX_PATCH\",  \"12288\"))\n",
    "TEMP_REWRITE    = float(os.environ.get(\"TEMP_REWRITE\", \"0.2\"))\n",
    "TEMP_PATCH      = float(os.environ.get(\"TEMP_PATCH\",   \"0.0\"))\n",
    "AUTO_PULL       = True\n",
    "ALLOW_CLI_FALLBACK = True\n",
    "MAX_REFINES     = 2\n",
    "PYTEST_TIMEOUT  = 90\n",
    "\n",
    "SEED = 7\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "plt.rcParams.update({\"axes.spines.top\": False, \"axes.spines.right\": False})\n",
    "\n",
    "# ------------------------------- TEXT/UTILITY -------------------------------\n",
    "WORD_RE   = re.compile(r\"[A-Za-z_][A-Za-z_0-9]*\")\n",
    "STOPWORDS = set(\"a an and are as at be by for from has have in is it its of on or that the to was were will with not this self none true false return def class if elif else try except finally while for\".split())\n",
    "Q_TOKENS  = set(\"\"\"\n",
    "x y z h s sdg t tdg rx ry rz rzz rzx rxy sx cx ccx cnot cz swap cswap iswap ecr u u1 u2 u3\n",
    "measure barrier qreg creg backend provider aer terra pulse schedule bind assign_parameters\n",
    "QuantumCircuit QuantumRegister ClassicalRegister Parameter ParameterVector\n",
    "DAGCircuit PassManager layout mapper transpile basis_gates optimization_level qasm dag layout pass\n",
    "CouplingMap AncillaAllocation NoiseModel Calibrations LayoutPass Unroller\n",
    "\"\"\".split())\n",
    "\n",
    "def safe_read(p: Path) -> str:\n",
    "    try: return p.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def tokenize(s: str) -> List[str]:\n",
    "    return [w.lower() for w in WORD_RE.findall(s) if w and w.lower() not in STOPWORDS]\n",
    "\n",
    "def changed_lines_in_A(a_text: str, b_text: str) -> set[int]:\n",
    "    a = a_text.splitlines(); b = b_text.splitlines()\n",
    "    sm = difflib.SequenceMatcher(None, a, b, autojunk=False)\n",
    "    touched=set()\n",
    "    for tag,i1,i2,j1,j2 in sm.get_opcodes():\n",
    "        if tag in (\"replace\",\"delete\"): touched.update(range(i1+1, i2+1))\n",
    "    return touched\n",
    "\n",
    "def dcg(scores): return sum(s/ math.log2(i+2) for i,s in enumerate(scores))\n",
    "def ecdf(arr): arr=np.asarray(arr,float); arr=arr[~np.isnan(arr)]; x=np.sort(arr); y=np.arange(1,len(x)+1)/max(1,len(x)); return x,y\n",
    "\n",
    "# ------------------------------- DATASET -------------------------------\n",
    "def iter_cases(db_root: Path):\n",
    "    for buggy in db_root.rglob(\"buggy.py\"):\n",
    "        d = buggy.parent\n",
    "        fixed=None\n",
    "        for nm in (\"fixed.py\",\"fix.py\"):\n",
    "            p=d/nm\n",
    "            if p.exists(): fixed=p; break\n",
    "        if fixed is None: continue\n",
    "        cid=str(d.relative_to(db_root)).replace(os.sep,\"/\")\n",
    "        yield cid, d, Path(buggy), Path(fixed)\n",
    "\n",
    "def top_tokens_query_from_text(text: str, k: int = 6) -> str:\n",
    "    toks=[w.lower() for w in WORD_RE.findall(text) if w and w.lower() not in STOPWORDS]\n",
    "    from collections import Counter\n",
    "    c=Counter(toks)\n",
    "    for w in (\"def\",\"class\",\"import\",\"return\",\"from\",\"if\",\"else\",\"raise\",\"assert\",\"self\"): c[w]=0\n",
    "    for t in list(Q_TOKENS)[:20]: c[t] *= 2\n",
    "    return \" \".join([w for w,_ in c.most_common(k)])\n",
    "\n",
    "# ------------------------------- CHUNKING / INDEX -------------------------------\n",
    "@dataclass\n",
    "class CodeChunk:\n",
    "    chunk_id: str; repo_key: str; file_path: str\n",
    "    start_line: int; end_line: int; symbol: str; kind: str; text: str\n",
    "\n",
    "class ASTChunker:\n",
    "    def __init__(self, window_fallback=80, window_overlap=10):\n",
    "        self.window_fallback=window_fallback; self.window_overlap=window_overlap\n",
    "    def chunk_file(self, case_dir: Path, file_path: Path, repo_key: str) -> List[CodeChunk]:\n",
    "        rel = str(file_path.relative_to(case_dir))\n",
    "        src = safe_read(file_path); lines = src.splitlines()\n",
    "        try: root = ast.parse(src)\n",
    "        except Exception: root = None\n",
    "        chunks=[]\n",
    "        def add(s,e,sym,kind):\n",
    "            s=max(1,int(s)); e=max(s,int(e))\n",
    "            chunks.append(CodeChunk(\n",
    "                chunk_id = md5(f\"{rel}:{s}-{e}\".encode()).hexdigest()[:12],\n",
    "                repo_key = repo_key, file_path=rel, start_line=s, end_line=e,\n",
    "                symbol=sym, kind=kind, text=\"\\n\".join(lines[s-1:e])\n",
    "            ))\n",
    "        if root is not None:\n",
    "            for node in ast.walk(root):\n",
    "                if isinstance(node,(ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                    s=getattr(node,\"lineno\",1); e=getattr(node,\"end_lineno\",s); sym=getattr(node,\"name\",\"<sym>\")\n",
    "                    add(s,e,sym,\"class\" if isinstance(node,ast.ClassDef) else \"function\")\n",
    "        if not chunks:\n",
    "            step=self.window_fallback-self.window_overlap; i=0; n=len(lines)\n",
    "            while i < n:\n",
    "                s=i+1; e=min(i+self.window_fallback, n); add(s,e,\"<module>\",\"module\"); i+=step\n",
    "        return chunks\n",
    "\n",
    "class _MiniBM25:\n",
    "    def __init__(self, docs):\n",
    "        from collections import Counter\n",
    "        self.docs=docs; self.N=len(docs); self.lens=[len(d) for d in docs]\n",
    "        self.avg = sum(self.lens)/max(1,self.N)\n",
    "        df=Counter()\n",
    "        for d in docs: df.update(set(d))\n",
    "        self.df=dict(df)\n",
    "    def idf(self,t):\n",
    "        df=self.df.get(t,0)\n",
    "        return 0.0 if df==0 else math.log(1+(self.N-df+0.5)/(df+0.5))\n",
    "    def score(self, q, doc, dl):\n",
    "        k1,b=1.5,0.75; from collections import Counter\n",
    "        f=Counter(doc); s=0.0\n",
    "        for t in q:\n",
    "            if t not in self.df: continue\n",
    "            tf=f.get(t,0)\n",
    "            if tf==0: continue\n",
    "            denom=tf+k1*(1-b+b*dl/max(1,self.avg))\n",
    "            s+=self.idf(t)*(tf*(k1+1))/denom\n",
    "        return s\n",
    "\n",
    "class HybridIndex:\n",
    "    \"\"\"BM25 with optional quantum-token boost via additive term.\"\"\"\n",
    "    def __init__(self, boost_map: Optional[Dict[str,float]]=None, include_paths: bool=False):\n",
    "        self.boost_map = {k.lower(): float(v) for k,v in (boost_map or {}).items()}\n",
    "        self.include_paths = include_paths\n",
    "        self.records=[]; self.docs=[]; self.bm25=None\n",
    "    def build(self, chunks: List[CodeChunk]):\n",
    "        self.records=[]; self.docs=[]\n",
    "        for c in chunks:\n",
    "            header = f\"{c.symbol} {c.kind} \"\n",
    "            if self.include_paths: header += c.file_path + \" \"\n",
    "            toks = tokenize(header + \"\\n\" + c.text)\n",
    "            boost_sum = sum(self.boost_map.get(t, 0.0) for t in toks)\n",
    "            self.records.append({\"chunk\":c, \"tokens\":toks, \"boost_sum\": float(boost_sum)})\n",
    "            self.docs.append(toks)\n",
    "        self.bm25 = _MiniBM25(self.docs)\n",
    "    def search(self, query: str, topk: int = 10):\n",
    "        q = tokenize(query)\n",
    "        scored=[]\n",
    "        for i, rec in enumerate(self.records):\n",
    "            s = self.bm25.score(q, rec[\"tokens\"], len(rec[\"tokens\"]))\n",
    "            s += 0.02 * rec.get(\"boost_sum\", 0.0)\n",
    "            scored.append((s,i))\n",
    "        scored.sort(reverse=True)\n",
    "        out=[]\n",
    "        for s,i in scored[:topk]:\n",
    "            c = self.records[i][\"chunk\"]\n",
    "            out.append({\n",
    "                \"score\": float(s), \"re_score\": 0.0,\n",
    "                \"file\": c.file_path, \"symbol\": c.symbol, \"kind\": c.kind,\n",
    "                \"start\": int(c.start_line), \"end\": int(c.end_line),\n",
    "                \"preview\": \"\\n\".join(c.text.splitlines()[:120]),\n",
    "            })\n",
    "        return out\n",
    "\n",
    "def quantum_boost_map(alpha: float = 1.8) -> Dict[str, float]:\n",
    "    return {t.lower(): alpha for t in Q_TOKENS}\n",
    "\n",
    "# ------------------------------- RERANK -------------------------------\n",
    "class CrossEncoderReranker:\n",
    "    def __init__(self, model_name: str):\n",
    "        try:\n",
    "            from sentence_transformers import CrossEncoder\n",
    "            self.model = CrossEncoder(model_name)\n",
    "            self.enabled=True\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] CrossEncoder unavailable:\", e)\n",
    "            self.model=None; self.enabled=False\n",
    "    def score_pairs(self, pairs: List[Tuple[str,str]]) -> np.ndarray:\n",
    "        if not self.enabled: return np.zeros(len(pairs))\n",
    "        return np.asarray(self.model.predict(pairs), dtype=float)\n",
    "\n",
    "def apply_rerank(query: str, pool_u: List[Dict], rr: Optional[CrossEncoderReranker]):\n",
    "    if rr is None or not rr.enabled: return pool_u\n",
    "    pairs=[(query, h.get(\"preview\",\"\")) for h in pool_u]\n",
    "    scores=rr.score_pairs(pairs)\n",
    "    for h,s in zip(pool_u, scores): h[\"re_score\"]=float(s)\n",
    "    return sorted(pool_u, key=lambda r: r.get(\"re_score\",0.0), reverse=True)\n",
    "\n",
    "# ------------------------------- SELECTORS / PRIORS -------------------------------\n",
    "def syntax_prior_of(hit: Dict) -> float:\n",
    "    txt = (hit.get(\"preview\",\"\") + \" \" + hit.get(\"symbol\",\"\")).lower()\n",
    "    prior = 0.0\n",
    "    if any(t in txt for t in [\"assert\",\"raise\",\"error\",\"exception\"]): prior += 0.10\n",
    "    if any(t.lower() in txt for t in Q_TOKENS):                       prior += 0.15\n",
    "    if re.search(r'\\b(run|apply)\\b', txt):                             prior += 0.12\n",
    "    if \"dag\" in txt or \"layout\" in txt:                                prior += 0.08\n",
    "    return prior\n",
    "\n",
    "def apply_syntax_prior(pool_u: List[Dict], alpha: float = 0.5):\n",
    "    out=[]\n",
    "    for h in pool_u:\n",
    "        sp = syntax_prior_of(h)\n",
    "        base = h.get(\"re_score\", h.get(\"score\", 0.0))\n",
    "        h2 = dict(h); h2[\"syn_prior\"] = sp\n",
    "        h2[\"score\"] = base * (1.0 + alpha*sp)\n",
    "        out.append(h2)\n",
    "    return sorted(out, key=lambda r: r.get(\"score\",0.0), reverse=True)\n",
    "\n",
    "def select_by_coverage_balanced(pool_u, topk, w_gain=0.8, w_base=1.0, w_rerank=1.5,\n",
    "                                w_div_file=0.15, w_div_sym=0.10, pen_overlap=0.10):\n",
    "    sel, covered = [], set()\n",
    "    seen_files, seen_syms = set(), set()\n",
    "    base = np.array([h.get(\"score\",0.0) for h in pool_u], dtype=float)\n",
    "    bn   = (base - base.min()) / (base.max() - base.min() + 1e-9)\n",
    "    rn   = np.array([h.get(\"re_score\",0.0) for h in pool_u], dtype=float)\n",
    "    for h,b,r in zip(pool_u, bn, rn):\n",
    "        h[\"_bn\"]=float(b); h[\"_rn\"]=float(r)\n",
    "    for _ in range(min(topk, len(pool_u))):\n",
    "        best, best_score=None, -1e9\n",
    "        for h in pool_u:\n",
    "            if h in sel: continue\n",
    "            rng=set(range(h[\"start\"], h[\"end\"]+1))\n",
    "            gain=len(rng - covered)\n",
    "            size=max(1, h[\"end\"]-h[\"start\"]+1)\n",
    "            gain_norm=gain/size\n",
    "            overlap_frac=1.0 - gain_norm\n",
    "            s  = w_gain*gain_norm + w_base*h[\"_bn\"] + w_rerank*h[\"_rn\"]\n",
    "            s += (w_div_file if h[\"file\"] not in seen_files else 0.0)\n",
    "            s += (w_div_sym  if h[\"symbol\"] not in seen_syms else 0.0)\n",
    "            s -= pen_overlap*overlap_frac\n",
    "            if s > best_score: best, best_score = h, s\n",
    "        if best is None: break\n",
    "        sel.append(best)\n",
    "        covered |= set(range(best[\"start\"], best[\"end\"]+1))\n",
    "        seen_files.add(best[\"file\"]); seen_syms.add(best[\"symbol\"])\n",
    "    return sel\n",
    "\n",
    "def select_by_coverage_old(hits, topk, w_new_file=10.0, w_new_symbol=6.0, w_rerank=2.0):\n",
    "    selected, covered = [], set()\n",
    "    seen_files, seen_symbols = set(), set()\n",
    "    pool = hits[:]\n",
    "    for _ in range(min(topk, len(pool))):\n",
    "        best, best_score = None, -1.0\n",
    "        for h in pool:\n",
    "            if h in selected: continue\n",
    "            rng = set(range(h[\"start\"], h[\"end\"] + 1))\n",
    "            gain = len(rng - covered)\n",
    "            tie  = h.get(\"re_score\", h.get(\"score\", 0.0))\n",
    "            s = gain + (w_new_file if h[\"file\"] not in seen_files else 0.0) \\\n",
    "                     + (w_new_symbol if h[\"symbol\"] not in seen_symbols else 0.0) \\\n",
    "                     + (w_rerank * tie)\n",
    "            if s > best_score:\n",
    "                best, best_score = h, s\n",
    "        if best is None: break\n",
    "        selected.append(best)\n",
    "        covered |= set(range(best[\"start\"], best[\"end\"] + 1))\n",
    "        seen_files.add(best[\"file\"]); seen_symbols.add(best[\"symbol\"])\n",
    "    return selected\n",
    "\n",
    "# ------------------------------- BUILD CHUNKS & INDICES -------------------------------\n",
    "all_chunks_ast, all_chunks_win, meta = [], [], {}\n",
    "chunker = ASTChunker()\n",
    "\n",
    "for cid, case_dir, bug_f, fix_f in iter_cases(DB_ROOT):\n",
    "    for ch in chunker.chunk_file(case_dir, bug_f, repo_key=cid):\n",
    "        ch.file_path = f\"{cid}/{ch.file_path}\"\n",
    "        all_chunks_ast.append(ch)\n",
    "    text = safe_read(bug_f); lines=text.splitlines()\n",
    "    win, overlap = 80, 10; step=max(1,win-overlap); i=0\n",
    "    while i < len(lines):\n",
    "        s=i+1; e=min(i+win, len(lines))\n",
    "        all_chunks_win.append(\n",
    "            CodeChunk(\n",
    "                chunk_id=md5(f\"{cid}/{bug_f.name}:{s}-{e}\".encode()).hexdigest()[:12],\n",
    "                repo_key=cid, file_path=f\"{cid}/{bug_f.name}\",\n",
    "                start_line=s, end_line=e, symbol=f\"<win@{s}-{e}>\", kind=\"module\",\n",
    "                text=\"\\n\".join(lines[s-1:e])\n",
    "            )\n",
    "        )\n",
    "        i+=step\n",
    "    bug_txt = text; fix_txt = safe_read(fix_f)\n",
    "    meta[cid] = {\"gold\": changed_lines_in_A(bug_txt, fix_txt),\n",
    "                 \"query\": top_tokens_query_from_text(bug_txt, k=6),\n",
    "                 \"project\": cid.split(\"/\")[0],\n",
    "                 \"paths\": {\"bug\": bug_f, \"fix\": fix_f}}\n",
    "\n",
    "def build_index(chunks, use_boost: bool):\n",
    "    boost = quantum_boost_map(1.8) if use_boost else {}\n",
    "    try:\n",
    "        idx = HybridIndex(boost_map=boost, include_paths=False)\n",
    "    except TypeError:\n",
    "        idx = HybridIndex()\n",
    "    idx.build(chunks); return idx\n",
    "\n",
    "idx_ast_base   = build_index(all_chunks_ast, use_boost=False)\n",
    "idx_ast_q      = build_index(all_chunks_ast, use_boost=True)\n",
    "idx_win_base   = build_index(all_chunks_win, use_boost=False)\n",
    "idx_win_q      = build_index(all_chunks_win, use_boost=True)\n",
    "\n",
    "# ------------------------------- SPLIT: 70/25/5 (train/val/test) -------------------------------\n",
    "ALL_CASES = sorted(meta.keys())\n",
    "# stable hashed order\n",
    "order = [ (c, md5(c.encode()).hexdigest()) for c in ALL_CASES ]\n",
    "order.sort(key=lambda t: t[1])\n",
    "ordered_cases = [c for c,_ in order]\n",
    "\n",
    "n = len(ordered_cases)\n",
    "n_train = int(round(0.70 * n))\n",
    "n_val   = int(round(0.25 * n))\n",
    "n_test  = max(0, n - n_train - n_val)  # ~5%\n",
    "\n",
    "TRAIN_CIDS = set(ordered_cases[:n_train])\n",
    "VAL_CIDS   = ordered_cases[n_train:n_train+n_val]\n",
    "TEST_CIDS  = ordered_cases[n_train+n_val:]\n",
    "\n",
    "with open(OUT_DIR/\"splits_70_25_5.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump({\"n\":n,\"train\":len(TRAIN_CIDS),\"val\":len(VAL_CIDS),\"test\":len(TEST_CIDS),\n",
    "               \"train_ids\":sorted(TRAIN_CIDS),\"val_ids\":VAL_CIDS,\"test_ids\":TEST_CIDS}, f, indent=2)\n",
    "\n",
    "print(f\"Split -> train={len(TRAIN_CIDS)} | val={len(VAL_CIDS)} | test={len(TEST_CIDS)}\")\n",
    "\n",
    "# Validation subset size knob (optional)\n",
    "if DATA_PERCENT not in (1, 100):\n",
    "    raise ValueError(\"DATA_PERCENT must be either 1 or 100.\")\n",
    "num_keep_val = max(1, int(math.ceil(len(VAL_CIDS)*DATA_PERCENT/100.0)))\n",
    "VAL_CIDS = [c for c,_h in sorted(((c, md5(c.encode()).hexdigest()) for c in VAL_CIDS),\n",
    "                                 key=lambda t:t[1])][:num_keep_val]\n",
    "print(f\"Validation cases usable: {len(VAL_CIDS)} (DATA_PERCENT={DATA_PERCENT})\")\n",
    "\n",
    "# ------------------------------- READ BEST CONFIG -------------------------------\n",
    "BEST_CONFIG = Path(BEST_CONFIG_PATH).read_text(encoding=\"utf-8\").strip().splitlines()[0]\n",
    "print(\"BEST_CONFIG (from file):\", BEST_CONFIG, \"(expect this to be TRAIN-only)\")\n",
    "\n",
    "def parse_cfg_name(name: str):\n",
    "    parts=name.split(\"__\")\n",
    "    return parts[0], (parts[1]==\"hint\"), parts[2], (parts[3]==\"rerank\"), (parts[4]==\"syntax\")\n",
    "\n",
    "def pick_index(chunking: str):\n",
    "    return {\"AST_base\": idx_ast_base, \"AST_q\": idx_ast_q, \"WIN_base\": idx_win_base, \"WIN_q\": idx_win_q}[chunking]\n",
    "\n",
    "def select_fn_from_name(selector: str):\n",
    "    return select_by_coverage_old if selector==\"old\" else select_by_coverage_balanced\n",
    "\n",
    "best_chunking, best_hints, best_selector, best_rerank, best_syntax = parse_cfg_name(BEST_CONFIG)\n",
    "best_index  = pick_index(best_chunking)\n",
    "best_select = select_fn_from_name(best_selector)\n",
    "rr_global   = CrossEncoderReranker(RERANK_MODEL) if best_rerank else None\n",
    "if rr_global is not None and not rr_global.enabled: rr_global=None\n",
    "\n",
    "# ------------------------------- FOCUS (tighten spans) -------------------------------\n",
    "FOCUS_MAX = 24; FOCUS_PAD = 3\n",
    "FOCUS_PAT = re.compile(\n",
    "    r\"(assert|raise|error|exception|todo|fixme|bug|fail|\"\n",
    "    r\"cx|rz|swap|measure|quantumcircuit|dagcircuit|layout|transpile|run\\(|apply\\()\",\n",
    "    re.I\n",
    ")\n",
    "def focus_span(hit: Dict, full_path: Path) -> Tuple[int,int,List[int]]:\n",
    "    s, e = int(hit[\"start\"]), int(hit[\"end\"])\n",
    "    try:\n",
    "        lines = full_path.read_text(encoding=\"utf-8\", errors=\"replace\").splitlines()\n",
    "    except Exception:\n",
    "        return s, e, []\n",
    "    seg = lines[s-1:e]\n",
    "    matches = [i for i,ln in enumerate(seg, start=s) if FOCUS_PAT.search(ln)]\n",
    "    if not matches:\n",
    "        mid = (s+e)//2\n",
    "        return max(1, mid - FOCUS_MAX//2), min(len(lines), max(1, mid - FOCUS_MAX//2) + FOCUS_MAX - 1), []\n",
    "    lo = max(1, min(matches) - FOCUS_PAD)\n",
    "    hi = min(len(lines), max(matches) + FOCUS_PAD)\n",
    "    if hi - lo + 1 > FOCUS_MAX:\n",
    "        hi = lo + FOCUS_MAX - 1\n",
    "    return lo, hi, [m for m in matches if lo <= m <= hi]\n",
    "\n",
    "# ------------------------------- LLM INFRA -------------------------------\n",
    "import requests\n",
    "def run(cmd, **kw): return subprocess.run(cmd, text=True, capture_output=True, **kw)\n",
    "def have_ollama_cli():\n",
    "    try: return run([\"ollama\",\"--version\"], timeout=5).returncode==0\n",
    "    except Exception: return False\n",
    "def _to_prompt(msgs):\n",
    "    system=[]; convo=[]\n",
    "    for m in msgs:\n",
    "        role=(m.get(\"role\") or \"user\").lower(); content=m.get(\"content\") or \"\"\n",
    "        if role==\"system\": system.append(content.strip())\n",
    "        elif role==\"user\":  convo.append(f\"USER:\\n{content}\\n\")\n",
    "        else:               convo.append(f\"ASSISTANT:\\n{content}\\n\")\n",
    "    return (\"\\n\".join(system).strip(), \"\".join(convo)+\"ASSISTANT:\\n\")\n",
    "def _http_json(url, payload, timeout=180):\n",
    "    r=requests.post(url, json=payload, timeout=timeout); r.raise_for_status(); return r.json()\n",
    "def _ollama_cli(msgs, model, temperature=0.2, num_ctx=8192, timeout=180):\n",
    "    sys_txt, prompt = _to_prompt(msgs)\n",
    "    env=os.environ.copy(); env[\"OLLAMA_NUM_CTX\"]=str(num_ctx)\n",
    "    p=run([\"ollama\",\"run\", model, prompt], timeout=timeout, env=env)\n",
    "    if p.returncode!=0: raise RuntimeError(p.stderr)\n",
    "    return p.stdout.strip()\n",
    "def ollama_chat(msgs, *, model, temperature, num_ctx, timeout=180):\n",
    "    try:\n",
    "        data=_http_json(f\"{OLLAMA_URL}/api/chat\", {\"model\":model,\"messages\":msgs,\"stream\":False,\"options\":{\"temperature\":temperature,\"num_ctx\":num_ctx}}, timeout=timeout)\n",
    "        return data.get(\"message\",{}).get(\"content\") or data.get(\"response\",\"\") or \"\".join(m.get(\"content\",\"\") for m in data.get(\"messages\",[]))\n",
    "    except Exception: pass\n",
    "    try:\n",
    "        sys_txt, prompt=_to_prompt(msgs)\n",
    "        payload={\"model\":model,\"prompt\":prompt,\"stream\":False,\"options\":{\"temperature\":temperature,\"num_ctx\":num_ctx}}\n",
    "        if sys_txt: payload[\"system\"]=sys_txt\n",
    "        data=_http_json(f\"{OLLAMA_URL}/api/generate\", payload, timeout=timeout)\n",
    "        return data.get(\"response\",\"\")\n",
    "    except Exception: pass\n",
    "    if ALLOW_CLI_FALLBACK and have_ollama_cli():\n",
    "        return _ollama_cli(msgs, model=model, temperature=temperature, num_ctx=num_ctx, timeout=timeout)\n",
    "    raise RuntimeError(\"Ollama not reachable (API and CLI failed).\")\n",
    "\n",
    "# ------------------------------- PROMPTS -------------------------------\n",
    "REWRITE_SYS = (\n",
    "    \"You are a software search assistant. Produce 3–8 SHORT queries (<=6 words) \"\n",
    "    \"to retrieve the buggy code. Prefer function/class names, module names, error keywords, \"\n",
    "    \"and quantum terms (cx, rz, swap, dag, layout, qasm, QuantumCircuit, DAGCircuit) only if relevant. \"\n",
    "    \"Return JSON: {'queries':['...']}. No prose.\"\n",
    ")\n",
    "PATCH_SYS = (\n",
    "    \"You are a senior Python engineer. Return STRICT JSON ONLY:\\n\"\n",
    "    \"{'edits':[{'file':'<rel path>','start':<int 1-based>,'end':<int>,'replacement':'<new full text lines start..end>'}],\"\n",
    "    \" 'rationale':'<one paragraph>'}\\n\"\n",
    "    \"HARD CONSTRAINTS:\\n\"\n",
    "    \" • Edit ONLY within the allowed line ranges provided.\\n\"\n",
    "    \" • Do NOT add new files; keep imports unless the context explicitly requires a change.\\n\"\n",
    "    \" • Keep changes minimal; preserve public APIs.\\n\"\n",
    "    \"QUANTUM GUARDRAILS:\\n\"\n",
    "    \" • Preserve qubit order and register semantics; do not swap classical/quantum registers.\\n\"\n",
    "    \" • Do not change pass interfaces (e.g., run(self, dag)).\\n\"\n",
    "    \" • Do not silently alter layout or coupling behavior.\\n\"\n",
    "    \"JSON only. No code fences.\"\n",
    ")\n",
    "def extract_json(s: str) -> dict:\n",
    "    m=re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", s, re.S)\n",
    "    raw=m.group(1) if m else s.strip()\n",
    "    return json.loads(raw)\n",
    "\n",
    "# ------------------------------- GUARDRAILS (deterministic checks) -------------------------------\n",
    "def _ast_ok(src: str) -> Tuple[bool, str]:\n",
    "    try:\n",
    "        ast.parse(src); return True, \"\"\n",
    "    except SyntaxError as e:\n",
    "        return False, f\"SyntaxError: {e.msg} at line {e.lineno}\"\n",
    "\n",
    "def _find_registers(src: str):\n",
    "    q_regs=set(); c_regs=set()\n",
    "    for m in re.finditer(r'(\\w+)\\s*=\\s*QuantumRegister\\(', src): q_regs.add(m.group(1))\n",
    "    for m in re.finditer(r'(\\w+)\\s*=\\s*ClassicalRegister\\(', src): c_regs.add(m.group(1))\n",
    "    return q_regs, c_regs\n",
    "\n",
    "def _pass_interface_ok(before_src: str, after_src: str) -> Tuple[bool,str]:\n",
    "    def sigs(s):\n",
    "        out=set()\n",
    "        try:\n",
    "            t=ast.parse(s)\n",
    "            for n in ast.walk(t):\n",
    "                if isinstance(n, ast.FunctionDef) and n.name==\"run\":\n",
    "                    out.add(tuple(a.arg for a in n.args.args))\n",
    "        except Exception: pass\n",
    "        return out\n",
    "    b=sigs(before_src); a=sigs(after_src)\n",
    "    if not b: return True, \"\"\n",
    "    if b != a: return False, f\"Pass interface changed: {b} -> {a}\"\n",
    "    return True, \"\"\n",
    "\n",
    "def _no_reg_mix_ok(src: str) -> Tuple[bool,str]:\n",
    "    q_regs, c_regs = _find_registers(src)\n",
    "    for m in re.finditer(r'measure\\s*\\(\\s*([A-Za-z_]\\w*)', src):\n",
    "        if m.group(1) in c_regs: return False, f\"measure() uses classical register '{m.group(1)}' as quantum\"\n",
    "    for m in re.finditer(r'(cx|cz|rz|rx|ry|swap)\\s*\\(\\s*([A-Za-z_]\\w*)', src):\n",
    "        if m.group(2) in c_regs: return False, f\"{m.group(1)}() uses classical register '{m.group(2)}' as quantum\"\n",
    "    return True, \"\"\n",
    "\n",
    "def _qubit_order_heuristic_ok(before_src: str, after_src: str, edited_ranges: List[Tuple[int,int]]) -> Tuple[bool,str]:\n",
    "    b_lines=before_src.splitlines(); a_lines=after_src.splitlines()\n",
    "    def slice_lines(lines, ranges):\n",
    "        out=[]\n",
    "        for s,e in ranges:\n",
    "            s=max(1,s); e=min(len(lines), max(s,e))\n",
    "            out.extend(lines[s-1:e])\n",
    "        return \"\\n\".join(out)\n",
    "    b=slice_lines(b_lines, edited_ranges)\n",
    "    a=slice_lines(a_lines, edited_ranges)\n",
    "    if re.search(r'\\bq\\[\\s*1\\s*\\]\\s*,\\s*q\\[\\s*0\\s*\\]', a) and re.search(r'\\bq\\[\\s*0\\s*\\]\\s*,\\s*q\\[\\s*1\\s*\\]', b):\n",
    "        return False, \"Potential qubit order swap in edited lines\"\n",
    "    return True, \"\"\n",
    "\n",
    "def guardrail_validate_patch(bug_file: Path, edits: List[Dict]) -> Tuple[bool, List[str]]:\n",
    "    before = safe_read(bug_file)\n",
    "    after  = before.splitlines()\n",
    "    ranges=[]\n",
    "    for e in edits or []:\n",
    "        s=max(1,int(e.get(\"start\",1))); en=int(e.get(\"end\",s))\n",
    "        replacement = str(e.get(\"replacement\",\"\")).splitlines()\n",
    "        after = after[:s-1] + replacement + after[en:]\n",
    "        ranges.append((s,en))\n",
    "    after_src = \"\\n\".join(after)\n",
    "    oks=[]; msgs=[]\n",
    "    ok,msg = _ast_ok(after_src); oks.append(ok);  (not ok) and msgs.append(msg)\n",
    "    ok,msg = _pass_interface_ok(before, after_src); oks.append(ok); (not ok) and msgs.append(msg)\n",
    "    ok,msg = _no_reg_mix_ok(after_src); oks.append(ok); (not ok) and msgs.append(msg)\n",
    "    ok,msg = _qubit_order_heuristic_ok(before, after_src, ranges); oks.append(ok); (not ok) and msgs.append(msg)\n",
    "    return all(oks), msgs\n",
    "\n",
    "# ------------------------------- DONOR FILTER (leak-free) -------------------------------\n",
    "def _case_from_hitfile(path_str: str) -> Optional[str]:\n",
    "    # file looks like: \"<cid>/buggy.py\" or \"<cid>/<relpath>\"\n",
    "    if not path_str: return None\n",
    "    parts = path_str.split(\"/\")\n",
    "    return \"/\".join(parts[:2]) if len(parts) >= 2 else None\n",
    "\n",
    "def donor_is_allowed_for_case(hit: Dict, current_cid: str) -> bool:\n",
    "    \"\"\"Allow same-case always. For cross-case, allow TRAIN only, and optionally exclude donor windows overlapping their own changes.\"\"\"\n",
    "    donor_cid = _case_from_hitfile(hit.get(\"file\",\"\"))\n",
    "    if donor_cid is None: return False\n",
    "    if donor_cid == current_cid:\n",
    "        return True\n",
    "    if not ALLOW_TRAIN_DONORS:\n",
    "        return False\n",
    "    if donor_cid not in TRAIN_CIDS:\n",
    "        return False\n",
    "    if not EXCLUDE_TRAIN_DONOR_CHANGED:\n",
    "        return True\n",
    "    # exclude if donor window overlaps donor's gold\n",
    "    gold = meta.get(donor_cid,{}).get(\"gold\", set())\n",
    "    s,e = int(hit.get(\"start\",1)), int(hit.get(\"end\",1))\n",
    "    return not any((ln in gold) for ln in range(s, e+1))\n",
    "\n",
    "# ------------------------------- EDIT HELPERS & RUN -------------------------------\n",
    "def enforce_in_region(edits: List[Dict], allowed: List[Tuple[int,int]]) -> List[Dict]:\n",
    "    ok=[]\n",
    "    for e in edits or []:\n",
    "        st=int(e.get(\"start\",1)); en=int(e.get(\"end\",st)); repl=e.get(\"replacement\",\"\")\n",
    "        for (a,b) in allowed:\n",
    "            if st>=a and en<=b:\n",
    "                ok.append({\"file\":e.get(\"file\",\"buggy.py\"), \"start\":st, \"end\":en, \"replacement\":repl})\n",
    "                break\n",
    "    return ok\n",
    "\n",
    "def apply_edits(src_repo: Path, edits: List[Dict], out_repo: Path) -> Path:\n",
    "    if out_repo.exists(): shutil.rmtree(out_repo)\n",
    "    shutil.copytree(src_repo, out_repo)\n",
    "    p=out_repo/\"buggy.py\"\n",
    "    if not p.exists(): return out_repo\n",
    "    lines=p.read_text(encoding=\"utf-8\",errors=\"replace\").splitlines()\n",
    "    for e in edits or []:\n",
    "        st, en = max(1,int(e[\"start\"])), min(len(lines), int(e[\"end\"]))\n",
    "        new = lines[:st-1] + str(e.get(\"replacement\",\"\")).splitlines() + lines[en:]\n",
    "        lines = new\n",
    "    p.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    return out_repo\n",
    "\n",
    "def run_pytest(path: Path, timeout=PYTEST_TIMEOUT):\n",
    "    try:\n",
    "        p = subprocess.run([sys.executable, \"-m\", \"pytest\", \"-q\"], cwd=path, text=True, capture_output=True, timeout=timeout)\n",
    "        return p.returncode, (p.stdout or \"\") + \"\\n\" + (p.stderr or \"\")\n",
    "    except Exception as e:\n",
    "        return 99, f\"(pytest error) {e}\"\n",
    "\n",
    "def last_failing_assert(trace: str) -> str:\n",
    "    tail = \"\\n\".join(trace.splitlines()[-120:])\n",
    "    m = re.search(r\"(E\\s+AssertionError[^\\n]*\\n(?:[^\\n]*\\n){0,6})\", tail)\n",
    "    return (m.group(1).strip() if m else tail[-400:].strip())\n",
    "\n",
    "def llm_rewrite_queries(seed_query: str) -> List[str]:\n",
    "    msgs=[{\"role\":\"system\",\"content\":REWRITE_SYS},\n",
    "          {\"role\":\"user\",\"content\":json.dumps({\"seed_query\":seed_query, \"rules\":[\"<=6 words/query\",\"no quotes/paths\"]})}]\n",
    "    out=ollama_chat(msgs, model=MODEL_REWRITE, temperature=TEMP_REWRITE, num_ctx=NUM_CTX_REWRITE)\n",
    "    try:\n",
    "        obj=extract_json(out)\n",
    "        if isinstance(obj, dict) and \"queries\" in obj: return [q.strip() for q in obj[\"queries\"] if isinstance(q,str) and q.strip()]\n",
    "        if isinstance(obj, list): return [q.strip() for q in obj if isinstance(q,str) and q.strip()]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return [q.strip(\"-• \").strip() for q in out.splitlines() if q.strip()][:6]\n",
    "\n",
    "def llm_patch_once(cid: str, focused_ctx: List[Dict], allowed_ranges: List[Tuple[int,int]], extra_feedback: str = \"\") -> dict:\n",
    "    payload={\"case\":cid,\n",
    "             \"allowed_ranges\":allowed_ranges,\n",
    "             \"context\":focused_ctx,\n",
    "             \"instruction\":\"Return strict JSON only. No markdown fences.\",\n",
    "             \"feedback\": extra_feedback}\n",
    "    msgs=[{\"role\":\"system\",\"content\":PATCH_SYS},\n",
    "          {\"role\":\"user\",\"content\":json.dumps(payload)}]\n",
    "    out=ollama_chat(msgs, model=MODEL_PATCH, temperature=TEMP_PATCH, num_ctx=NUM_CTX_PATCH)\n",
    "    try:\n",
    "        return extract_json(out)\n",
    "    except Exception:\n",
    "        msgs.append({\"role\":\"system\",\"content\":\"Your previous output was not valid JSON. Return ONLY JSON now.\"})\n",
    "        out2=ollama_chat(msgs, model=MODEL_PATCH, temperature=0.0, num_ctx=NUM_CTX_PATCH)\n",
    "        return extract_json(out2)\n",
    "\n",
    "# ------------------------------- SCORING / DIAGNOSTICS -------------------------------\n",
    "def evaluate_candidate(bug_repo: Path, fix_repo: Path, cand_repo: Optional[Path]) -> Dict[str, Any]:\n",
    "    a = safe_read(bug_repo/\"buggy.py\").splitlines()\n",
    "    b = safe_read(fix_repo/\"buggy.py\").splitlines()\n",
    "    c = safe_read(cand_repo/\"buggy.py\").splitlines() if cand_repo and (cand_repo/\"buggy.py\").exists() else []\n",
    "    def _touched(x,y):\n",
    "        sm = difflib.SequenceMatcher(None, x, y, autojunk=False)\n",
    "        touched=set()\n",
    "        for tag,i1,i2,j1,j2 in sm.get_opcodes():\n",
    "            if tag in (\"replace\",\"delete\"):\n",
    "                touched.update(range(i1+1,i2+1))\n",
    "        return touched\n",
    "    gold=_touched(a,b); pred=_touched(a,c) if c else set()\n",
    "    inter=len(gold & pred)\n",
    "    lp = inter / max(1,len(pred))\n",
    "    lr = inter / max(1,len(gold))\n",
    "    lf = 0.0 if lp+lr==0 else 2*lp*lr/(lp+lr)\n",
    "    return {\"lines_p\":lp,\"lines_r\":lr,\"lines_f1\":lf}\n",
    "\n",
    "def count_lines_edited(bug_repo: Path, edits: List[Dict]) -> Tuple[int,int]:\n",
    "    src_lines = safe_read(bug_repo/\"buggy.py\").splitlines()\n",
    "    touched=0; delta=0\n",
    "    for e in edits or []:\n",
    "        st=max(1,int(e.get(\"start\",1))); en=int(e.get(\"end\",st))\n",
    "        repl = str(e.get(\"replacement\",\"\")).splitlines()\n",
    "        old_len = en-st+1\n",
    "        touched += max(0, old_len)\n",
    "        delta += abs(len(repl) - old_len)\n",
    "    return touched, delta\n",
    "\n",
    "def api_drift_score(before: str, after: str) -> float:\n",
    "    def names(s):\n",
    "        try:\n",
    "            t=ast.parse(s); out=set()\n",
    "            for n in ast.walk(t):\n",
    "                if isinstance(n, ast.FunctionDef): out.add((\"fun\", n.name, len(n.args.args)))\n",
    "                if isinstance(n, ast.ClassDef):    out.add((\"cls\", n, 0))\n",
    "            return out\n",
    "        except Exception:\n",
    "            return set()\n",
    "    b=names(before); a=names(after)\n",
    "    if not b and not a: return 0.0\n",
    "    j = len(b & a)/max(1,len(b | a))\n",
    "    return 1.0 - j\n",
    "\n",
    "def identifier_jaccard(before: str, after: str) -> float:\n",
    "    B=set(tokenize(before)); A=set(tokenize(after))\n",
    "    if not (A or B): return 1.0\n",
    "    return len(A & B)/max(1,len(A | B))\n",
    "\n",
    "def distortion_flags(bug_repo: Path, edits: List[Dict], cand_repo: Optional[Path], lines_f1: float) -> Dict[str, Any]:\n",
    "    before = safe_read(bug_repo/\"buggy.py\")\n",
    "    after  = safe_read(cand_repo/\"buggy.py\") if cand_repo and (cand_repo/\"buggy.py\").exists() else \"\"\n",
    "    ast_ok, _ = _ast_ok(after) if after else (False,\"\")\n",
    "    drift    = api_drift_score(before, after) if after else np.nan\n",
    "    jacc     = identifier_jaccard(before, after) if after else np.nan\n",
    "    touched, delta = count_lines_edited(bug_repo, edits)\n",
    "    excessive_no_gain = (lines_f1==0.0 and delta>=5)\n",
    "    flags = {\n",
    "        \"ast_parse_fail\": (not ast_ok),\n",
    "        \"api_drift_gt40\": bool(drift!=drift and False or (drift>0.40)),\n",
    "        \"id_jacc_lt60\":   bool(jacc!=jacc and False or (jacc<0.60)),\n",
    "        \"excessive_no_gain\": excessive_no_gain,\n",
    "        \"drift\": float(drift if drift==drift else np.nan),\n",
    "        \"id_jacc\": float(jacc if jacc==jacc else np.nan),\n",
    "        \"delta_abs_lines\": int(delta),\n",
    "        \"lines_touched\": int(touched)\n",
    "    }\n",
    "    return flags\n",
    "\n",
    "# ------------------------------- GRAP-Q AGENT RUN (VAL only) -------------------------------\n",
    "def run_grap_once(case_ids: List[str],label: str = \"VAL\"):\n",
    "    rows=[]; logs_all=[]\n",
    "    for cid in tqdm(case_ids, desc=\"[GRAP-Q|VAL] cases\"):\n",
    "        q0 = meta[cid][\"query\"]\n",
    "        q  = (q0 + \" cx rz dag\") if best_hints else q0\n",
    "        # retrieval pool (global index, then donor filter)\n",
    "        pool = best_index.search(q, topk=max(OVERRETRIEVE, 6*TOPK))\n",
    "        pool = [h for h in pool if donor_is_allowed_for_case(h, cid)]\n",
    "        # rerank\n",
    "        pool = apply_rerank(q, pool, rr_global)\n",
    "        # syntax prior (if config says syntax)\n",
    "        pool = apply_syntax_prior(pool, alpha=0.5) if best_syntax else pool\n",
    "        # select\n",
    "        select_fn = best_select\n",
    "        selected  = select_fn(pool, TOPK)\n",
    "        # focus windows\n",
    "        bug_path  = meta[cid][\"paths\"][\"bug\"]\n",
    "        focused_ctx=[]; allowed=[]\n",
    "        for i,h in enumerate(selected,1):\n",
    "            lo,hi,_ = focus_span(h, bug_path)\n",
    "            allowed.append((lo,hi))\n",
    "            snippet = safe_read(bug_path).splitlines()[lo-1:hi]\n",
    "            focused_ctx.append({\"rank\":i,\"file\":h[\"file\"],\"span\":f\"{lo}-{hi}\",\"symbol\":h[\"symbol\"],\"code\":\"\\n\".join(snippet)})\n",
    "        # tiny repos\n",
    "        tiny_b = WORK_DIR / f\"{cid.replace('/','__')}__g_bug\"; tiny_f = WORK_DIR / f\"{cid.replace('/','__')}__g_fix\"\n",
    "        if tiny_b.exists(): shutil.rmtree(tiny_b)\n",
    "        if tiny_f.exists(): shutil.rmtree(tiny_f)\n",
    "        tiny_b.mkdir(parents=True, exist_ok=True); tiny_f.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(meta[cid][\"paths\"][\"bug\"], tiny_b/\"buggy.py\"); shutil.copy(meta[cid][\"paths\"][\"fix\"], tiny_f/\"buggy.py\")\n",
    "        # refine loop with guardrails\n",
    "        feedback=\"\"; patch={\"edits\":[],\"rationale\":\"\"}; cand_repo=None; guard_notes=[]; rationale_autofill=False; autofill_reason=\"\"\n",
    "        for it in range(MAX_REFINES+1):\n",
    "            proposal = llm_patch_once(cid, focused_ctx, allowed, extra_feedback=feedback)\n",
    "            # rationale auto-fill tracker\n",
    "            if not isinstance(proposal.get(\"rationale\",\"\"), str) or not proposal.get(\"rationale\",\"\").strip():\n",
    "                proposal[\"rationale\"] = \"Autofill: minimal, localized fix within allowed span; keep APIs/layout/register semantics; address failure indicated by guardrails/tests.\"\n",
    "                rationale_autofill=True; autofill_reason=\"missing_or_empty\"\n",
    "            edits = enforce_in_region(proposal.get(\"edits\",[]), allowed)\n",
    "            ok, reasons = guardrail_validate_patch(tiny_b/\"buggy.py\", edits)\n",
    "            if not ok:\n",
    "                feedback = \"Guardrail violations:\\n- \" + \"\\n- \".join(reasons) + \"\\nFix minimally within allowed ranges.\"\n",
    "                guard_notes.extend(reasons)\n",
    "                if it==MAX_REFINES: break\n",
    "                continue\n",
    "            patch={\"edits\":edits,\"rationale\":proposal.get(\"rationale\",\"\")}\n",
    "            cand_repo = WORK_DIR / f\"{cid.replace('/','__')}__g_cand\"\n",
    "            apply_edits(tiny_b, edits, cand_repo)\n",
    "            # syntax check\n",
    "            src = safe_read(cand_repo/\"buggy.py\")\n",
    "            ok,_ = _ast_ok(src)\n",
    "            if not ok:\n",
    "                feedback = \"Your edit produced a SyntaxError. Repair minimally.\"\n",
    "                guard_notes.append(\"syntax_fail_after_apply\")\n",
    "                if it==MAX_REFINES: break\n",
    "                continue\n",
    "            # pytest run for feedback (even if tests absent)\n",
    "            rc, out = run_pytest(cand_repo, timeout=PYTEST_TIMEOUT)\n",
    "            if rc==0:\n",
    "                break\n",
    "            if rc in (5, 4):\n",
    "                feedback=\"No runnable tests. Ensure edit compiles and is minimal.\"\n",
    "            else:\n",
    "                feedback=\"Last failing assertion/stack:\\n\"+last_failing_assert(out)\n",
    "            if it==MAX_REFINES: break\n",
    "\n",
    "        rep = evaluate_candidate(tiny_b, tiny_f, cand_repo)\n",
    "        touched, delta = count_lines_edited(tiny_b, patch.get(\"edits\",[]))\n",
    "        flags = distortion_flags(tiny_b, patch.get(\"edits\",[]), cand_repo, rep[\"lines_f1\"])\n",
    "        rows.append({\n",
    "            \"case\": cid, \"method\":\"GRAP\", \"lines_f1\":rep[\"lines_f1\"], \"lines_p\":rep[\"lines_p\"], \"lines_r\":rep[\"lines_r\"],\n",
    "            \"num_edits\": len(patch.get(\"edits\",[])), \"lines_touched\": touched, \"delta_abs_lines\": delta,\n",
    "            \"rationale_autofill\": bool(rationale_autofill),\n",
    "            **flags\n",
    "        })\n",
    "        logs_all.append({\"case\":cid,\"guardrail_notes\":guard_notes,\"selected\":selected,\"allowed\":allowed,\n",
    "                         \"patch\":patch,\"rationale_autofill\":rationale_autofill,\"autofill_reason\":autofill_reason})\n",
    "    df=pd.DataFrame(rows)\n",
    "    df.to_csv(OUT_DIR / f\"llm_results_{label.lower()}.csv\", index=False)\n",
    "\n",
    "    with open(OUT_DIR/\"grap_logs_val.json\",\"w\",encoding=\"utf-8\") as f: json.dump(logs_all, f, indent=2)\n",
    "    return df\n",
    "\n",
    "# ------------------------------- PURE LLM RUN (VAL only) -------------------------------\n",
    "def run_pure_llm_once(case_ids: List[str],label: str = \"VAL\"):\n",
    "    rows=[]; logs_all=[]\n",
    "    for cid in tqdm(case_ids, desc=\"[Pure-LLM|VAL] cases\"):\n",
    "        bug_path = meta[cid][\"paths\"][\"bug\"]; fix_path = meta[cid][\"paths\"][\"fix\"]\n",
    "        code = \"\\n\".join(safe_read(bug_path).splitlines()[:220])\n",
    "        ctx = [{\"rank\":1,\"file\":f\"{cid}/buggy.py\",\"span\":\"1-220\",\"symbol\":\"<file>\",\"code\":code}]\n",
    "        msgs=[{\"role\":\"system\",\"content\":PATCH_SYS},\n",
    "              {\"role\":\"user\",\"content\":json.dumps({\"case\":cid,\"context\":ctx,\"instruction\":\"Return strict JSON only.\"})}]\n",
    "        rationale_autofill=False; autofill_reason=\"\"\n",
    "        try:\n",
    "            out=ollama_chat(msgs, model=MODEL_PATCH, temperature=TEMP_PATCH, num_ctx=NUM_CTX_PATCH)\n",
    "            patch=extract_json(out)\n",
    "        except Exception as e:\n",
    "            patch={\"edits\":[],\"rationale\":f\"error: {e}\"}\n",
    "        if not isinstance(patch.get(\"rationale\",\"\"), str) or not patch.get(\"rationale\",\"\").strip():\n",
    "            patch[\"rationale\"] = \"Autofill: file-level attempt based on first 220 lines; keep APIs/layout/register semantics; apply smallest plausible fix.\"\n",
    "            rationale_autofill=True; autofill_reason=\"missing_or_empty\"\n",
    "        edits = patch.get(\"edits\",[]) or []\n",
    "        tiny_b = WORK_DIR / f\"{cid.replace('/','__')}__p_bug\"; tiny_f = WORK_DIR / f\"{cid.replace('/','__')}__p_fix\"\n",
    "        if tiny_b.exists(): shutil.rmtree(tiny_b)\n",
    "        if tiny_f.exists(): shutil.rmtree(tiny_f)\n",
    "        tiny_b.mkdir(parents=True, exist_ok=True); tiny_f.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(bug_path, tiny_b/\"buggy.py\"); shutil.copy(fix_path, tiny_f/\"buggy.py\")\n",
    "        cand_repo=None\n",
    "        if edits:\n",
    "            cand_repo = WORK_DIR / f\"{cid.replace('/','__')}__p_cand\"\n",
    "            apply_edits(tiny_b, edits, cand_repo)\n",
    "        rep = evaluate_candidate(tiny_b, tiny_f, cand_repo)\n",
    "        touched, delta = count_lines_edited(tiny_b, edits)\n",
    "        flags = distortion_flags(tiny_b, edits, cand_repo, rep[\"lines_f1\"])\n",
    "        rows.append({\n",
    "            \"case\": cid, \"method\":\"LLM\", \"lines_f1\":rep[\"lines_f1\"], \"lines_p\":rep[\"lines_p\"], \"lines_r\":rep[\"lines_r\"],\n",
    "            \"num_edits\": len(edits), \"lines_touched\": touched, \"delta_abs_lines\": delta,\n",
    "            \"rationale_autofill\": bool(rationale_autofill),\n",
    "            **flags\n",
    "        })\n",
    "        logs_all.append({\"case\":cid,\"patch\":patch,\"rationale_autofill\":rationale_autofill,\"autofill_reason\":autofill_reason})\n",
    "    df=pd.DataFrame(rows)\n",
    "    df.to_csv(OUT_DIR/\"llm_results_val.csv\", index=False)\n",
    "    with open(OUT_DIR/\"llm_logs_val.json\",\"w\",encoding=\"utf-8\") as f: json.dump(logs_all, f, indent=2)\n",
    "    return df\n",
    "\n",
    "# ------------------------------- RUN BOTH (VAL) & MERGE -------------------------------\n",
    "df_grap = run_grap_once(VAL_CIDS)\n",
    "df_llm  = run_pure_llm_once(VAL_CIDS)\n",
    "df_all  = pd.concat([df_grap, df_llm], ignore_index=True)\n",
    "df_wide = df_all.pivot(index=\"case\", columns=\"method\", values=\"lines_f1\")\n",
    "df_all.to_csv(OUT_DIR/\"combined_results_val.csv\", index=False)\n",
    "\n",
    "# ------------------------------- STATS & PLOTS (Validation only) -------------------------------\n",
    "def savefig(path): Path(path).parent.mkdir(parents=True, exist_ok=True); plt.tight_layout(); plt.savefig(path); plt.close()\n",
    "def mean_ci95(a):\n",
    "    a=np.asarray(pd.to_numeric(a, errors=\"coerce\").dropna(), float)\n",
    "    if len(a)==0: return np.nan, (np.nan, np.nan)\n",
    "    m=a.mean(); se=a.std(ddof=1)/np.sqrt(len(a)) if len(a)>1 else 0.0\n",
    "    return m, (m-1.96*se, m+1.96*se)\n",
    "\n",
    "# 1) Macro bar (mean ± 95% CI) Lines-F1\n",
    "m_g,ci_g = mean_ci95(df_grap[\"lines_f1\"])\n",
    "m_l,ci_l = mean_ci95(df_llm[\"lines_f1\"])\n",
    "plt.figure(figsize=(6,4))\n",
    "means=[m_g,m_l]; cis=[ci_g,ci_l]; xs=np.arange(2)\n",
    "plt.bar(xs, means, yerr=[[means[i]-cis[i][0] for i in range(2)],[cis[i][1]-means[i] for i in range(2)]], capsize=6)\n",
    "plt.xticks(xs, [\"GRAP-Q\",\"Pure-LLM\"]); plt.ylim(0,1); plt.ylabel(\"Lines-F1\"); plt.title(\"Macro comparison (VAL, mean ± 95% CI)\")\n",
    "savefig(OUT_DIR/\"macro_linesf1_bar_val.png\")\n",
    "\n",
    "# 2) ECDF Lines-F1\n",
    "plt.figure(figsize=(6,4))\n",
    "x,y = ecdf(df_grap[\"lines_f1\"]); plt.plot(x,y,label=\"GRAP-Q\")\n",
    "x,y = ecdf(df_llm[\"lines_f1\"]);  plt.plot(x,y,label=\"Pure-LLM\")\n",
    "plt.xlabel(\"Lines-F1\"); plt.ylabel(\"ECDF\"); plt.title(\"Distribution of effectiveness (VAL)\"); plt.legend()\n",
    "savefig(OUT_DIR/\"ecdf_linesf1_val.png\")\n",
    "\n",
    "# 3) Patch minimality: Δ lines edited vs Lines-F1\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(df_grap[\"delta_abs_lines\"], df_grap[\"lines_f1\"], label=\"GRAP-Q\")\n",
    "plt.scatter(df_llm[\"delta_abs_lines\"],  df_llm[\"lines_f1\"],  label=\"Pure-LLM\", marker=\"x\")\n",
    "plt.xlabel(\"Δ lines edited (abs)\"); plt.ylabel(\"Lines-F1\"); plt.title(\"Patch minimality vs correctness (VAL)\"); plt.legend()\n",
    "savefig(OUT_DIR/\"scatter_minimality_val.png\")\n",
    "\n",
    "# 4) Edit efficiency: Lines-F1 per 10 edited lines\n",
    "def efficiency(df): \n",
    "    d = pd.to_numeric(df[\"delta_abs_lines\"], errors=\"coerce\").fillna(0.0)\n",
    "    return pd.to_numeric(df[\"lines_f1\"], errors=\"coerce\").fillna(0.0) / (d.replace(0, np.nan)/10.0)\n",
    "eff_g = efficiency(df_grap); eff_l = efficiency(df_llm)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot([eff_g.dropna(), eff_l.dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
    "plt.ylabel(\"Lines-F1 per 10 edited lines\"); plt.title(\"Edit efficiency (VAL, higher is better)\")\n",
    "savefig(OUT_DIR/\"box_efficiency_val.png\")\n",
    "\n",
    "# 5) Distortion rates (stacked)\n",
    "def rate(df, col): s=pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(bool); return float(s.mean())\n",
    "rates = pd.DataFrame({\n",
    "    \"syntax_fail\":[rate(df_grap,\"ast_parse_fail\"), rate(df_llm,\"ast_parse_fail\")],\n",
    "    \"api_drift>0.40\":[rate(df_grap,\"api_drift_gt40\"), rate(df_llm,\"api_drift_gt40\")],\n",
    "    \"id_jacc<0.60\":[rate(df_grap,\"id_jacc_lt60\"), rate(df_llm,\"id_jacc_lt60\")],\n",
    "    \"excessive_no_gain\":[rate(df_grap,\"excessive_no_gain\"), rate(df_llm,\"excessive_no_gain\")]\n",
    "}, index=[\"GRAP-Q\",\"Pure-LLM\"])\n",
    "bottom=np.zeros(2)\n",
    "plt.figure(figsize=(7.2,4.2))\n",
    "for col in rates.columns:\n",
    "    plt.bar([\"GRAP-Q\",\"Pure-LLM\"], rates[col].values, bottom=bottom, label=col)\n",
    "    bottom += rates[col].values\n",
    "plt.ylim(0,1); plt.ylabel(\"share of cases\"); plt.title(\"Distortion/Failure modes (VAL, lower is better)\"); plt.legend(fontsize=8, ncol=2)\n",
    "savefig(OUT_DIR/\"distortion_rates_stacked_val.png\")\n",
    "\n",
    "# 6) Hist overlays: Δ lines edited\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(pd.to_numeric(df_grap[\"delta_abs_lines\"], errors=\"coerce\"), bins=20, alpha=0.6, label=\"GRAP-Q\")\n",
    "plt.hist(pd.to_numeric(df_llm[\"delta_abs_lines\"], errors=\"coerce\"),  bins=20, alpha=0.6, label=\"Pure-LLM\")\n",
    "plt.xlabel(\"Δ lines edited (abs)\"); plt.ylabel(\"count\"); plt.title(\"Patch size distribution (VAL)\"); plt.legend()\n",
    "savefig(OUT_DIR/\"hist_patch_size_val.png\")\n",
    "\n",
    "# 7) Boxplots of precision/recall\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot([pd.to_numeric(df_grap[\"lines_p\"], errors=\"coerce\").dropna(),\n",
    "             pd.to_numeric(df_llm[\"lines_p\"],  errors=\"coerce\").dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
    "plt.title(\"Line-level Precision (VAL)\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot([pd.to_numeric(df_grap[\"lines_r\"], errors=\"coerce\").dropna(),\n",
    "             pd.to_numeric(df_llm[\"lines_r\"],  errors=\"coerce\").dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
    "plt.title(\"Line-level Recall (VAL)\"); plt.tight_layout()\n",
    "savefig(OUT_DIR/\"box_precision_recall_val.png\")\n",
    "\n",
    "# 8) Win-rate (per-case head-to-head Lines-F1)\n",
    "joined = df_wide.dropna()\n",
    "wins  = float((joined[\"GRAP\"] > joined[\"LLM\"]).mean())\n",
    "loss  = float((joined[\"GRAP\"] < joined[\"LLM\"]).mean())\n",
    "ties  = float((joined[\"GRAP\"] == joined[\"LLM\"]).mean())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"GRAP better\",\"LLM better\",\"Tie\"], [wins,loss,ties])\n",
    "plt.ylim(0,1); plt.ylabel(\"share of cases\"); plt.title(\"Head-to-head win-rate (VAL)\")\n",
    "savefig(OUT_DIR/\"winrate_val.png\")\n",
    "\n",
    "# 9) Paired Lines-F1 (sorted by GRAP−LLM)\n",
    "diff = (joined[\"GRAP\"] - joined[\"LLM\"]).sort_values()\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(range(len(diff)), diff.values)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"cases (sorted)\"); plt.ylabel(\"GRAP − LLM (Lines-F1)\"); plt.title(\"Per-case advantage (VAL)\")\n",
    "savefig(OUT_DIR/\"paired_diff_curve_val.png\")\n",
    "\n",
    "# 10) API drift & identifier Jaccard distributions\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot([pd.to_numeric(df_grap[\"drift\"], errors=\"coerce\").dropna(),\n",
    "             pd.to_numeric(df_llm[\"drift\"],  errors=\"coerce\").dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
    "plt.title(\"API drift (1−Jaccard of API, VAL)\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot([pd.to_numeric(df_grap[\"id_jacc\"], errors=\"coerce\").dropna(),\n",
    "             pd.to_numeric(df_llm[\"id_jacc\"],  errors=\"coerce\").dropna()], labels=[\"GRAP-Q\",\"Pure-LLM\"], showmeans=True)\n",
    "plt.title(\"Identifier Jaccard (VAL)\"); plt.tight_layout()\n",
    "savefig(OUT_DIR/\"box_api_id_jacc_val.png\")\n",
    "\n",
    "# 11) Efficiency scatter with LSQ trend lines\n",
    "def scatter_with_trend(x, y, label):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\").fillna(0).values.astype(float)\n",
    "    y = pd.to_numeric(y, errors=\"coerce\").fillna(0).values.astype(float)\n",
    "    plt.scatter(x, y, label=label, alpha=0.7)\n",
    "    if len(x)>=2:\n",
    "        A = np.vstack([x, np.ones(len(x))]).T\n",
    "        m, c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        xs = np.linspace(0, max(x)+1, 100)\n",
    "        plt.plot(xs, m*xs+c)\n",
    "plt.figure(figsize=(7,4))\n",
    "scatter_with_trend(df_grap[\"delta_abs_lines\"], df_grap[\"lines_f1\"], \"GRAP-Q\")\n",
    "scatter_with_trend(df_llm[\"delta_abs_lines\"],  df_llm[\"lines_f1\"],  \"Pure-LLM\")\n",
    "plt.xlabel(\"Δ lines edited\"); plt.ylabel(\"Lines-F1\"); plt.title(\"Efficiency trendlines (VAL)\"); plt.legend()\n",
    "savefig(OUT_DIR/\"scatter_trend_efficiency_val.png\")\n",
    "\n",
    "print(\"\\nVALIDATION comparison artifacts saved to:\", OUT_DIR.resolve())\n",
    "print(\"BEST_CONFIG used:\", BEST_CONFIG)\n",
    "print(\"Donor policy -> TRAIN only:\", ALLOW_TRAIN_DONORS, \"| exclude donor-changed windows:\", EXCLUDE_TRAIN_DONOR_CHANGED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c636c06",
   "metadata": {},
   "source": [
    "# RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic Mode\n",
    "!python GRAP-Q.py \\\n",
    "  --mode diagnostic \\\n",
    "  --best_config results/qeval_ablation_plus/best_config.txt \\\n",
    "  --db_root data/bugs4q/Bugs4Q-Database \\\n",
    "  --out_dir results/infer \\\n",
    "  --work_dir .work/infer \\\n",
    "  --data_percent_test 100\n",
    "\n",
    "## Test Mode\n",
    "!python GRAP-Q.py \\\n",
    "  --mode test \\\n",
    "  --best_config results/qeval_ablation_plus/best_config.txt \\\n",
    "  --db_root data/bugs4q/Bugs4Q-Database \\\n",
    "  --out_dir results/infer \\\n",
    "  --work_dir .work/infer \\\n",
    "  --data_percent_test 100\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
